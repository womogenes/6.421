{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b4c5acf0637a46d9b75ae4e31b124c33",
    "deepnote_cell_type": "markdown",
    "id": "w7C_Q2UbkGas"
   },
   "source": [
    "# **Door Opening**\n",
    "\n",
    "In the lecture, we've seen an example of a robot manipulating a cylindrical object in the DARPA Robotics Challenge.  Similarly, by using optimization-based inverse kinematics, we will solve a series of IK problems that can open a cupboard door. You can take a look at the [interactive_ik](https://deepnote.com/workspace/Manipulation-ac8201a1-470a-4c77-afd0-2cc45bc229ff/project/0762b167-402a-4362-9702-7d559f0e73bb/notebook/interactive_ik-b6b0708a94b340b7b17cedbcc3d2d053?secondary-sidebar-autoopen=true&secondary-sidebar=agent) notebook, which illustrates many of the concepts we go through in this notebook.\n",
    "\n",
    "**Learning Objectives**\n",
    "- Formulate inverse kinematics problems with a joint-centering cost, position constraints and orientation constraints.\n",
    "- Apply IK to a real-world task of opening a door.\n",
    "\n",
    "**What You'll Implement**\n",
    "- Set up the IK problem for a door-opening task by specifying the cost function and constraints.\n",
    "- Solve the IK program over a trajectory of poses to generate a sequence of joint configurations that accomplishes the door-opening motion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "aa6587baade74f7b9652b719dde0d70a",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Setup and Imports\n",
    "\n",
    "Let us first import our standard drake functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "926f15cc0b7c4fc8999d68e71b4021da",
    "deepnote_cell_type": "code",
    "execution_context_id": "8121b1bb-b4b2-4c8d-b0a7-a27c6d98adad",
    "execution_millis": 1,
    "execution_start": 1759156442273,
    "id": "sXAaoUZHGM6e",
    "source_hash": "46621c14"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pydrake.all import (\n",
    "    ConstantVectorSource,\n",
    "    DiagramBuilder,\n",
    "    InverseKinematics,\n",
    "    MultibodyPlant,\n",
    "    Parser,\n",
    "    PiecewisePolynomial,\n",
    "    PiecewiseQuaternionSlerp,\n",
    "    RigidTransform,\n",
    "    RollPitchYaw,\n",
    "    RotationMatrix,\n",
    "    Simulator,\n",
    "    Solve,\n",
    "    StartMeshcat,\n",
    "    Trajectory,\n",
    "    TrajectorySource,\n",
    ")\n",
    "from pydrake.multibody import inverse_kinematics\n",
    "from pydrake.trajectories import PiecewisePolynomial\n",
    "\n",
    "from manipulation.meshcat_utils import AddMeshcatTriad\n",
    "from manipulation.scenarios import AddMultibodyTriad\n",
    "from manipulation.station import LoadScenario, MakeHardwareStation, MakeMultibodyPlant\n",
    "from manipulation.utils import FindResource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "4de11a74ede0412893a2853db6472fec",
    "deepnote_cell_type": "code",
    "execution_context_id": "8121b1bb-b4b2-4c8d-b0a7-a27c6d98adad",
    "execution_millis": 10,
    "execution_start": 1759156444213,
    "source_hash": "6d42057f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:drake:Meshcat listening for connections at http://localhost:7000\n"
     ]
    }
   ],
   "source": [
    "# Start the visualizer.\n",
    "meshcat = StartMeshcat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "98e1cb7352c44d6c9e9f127b5479ea01",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Part 1: Visualizing the end effector trajectory\n",
    "\n",
    "The goal of this notebook is to command the iiwa to open a cupboard door. We choose to open the door on the right. In the cell below, we provided you with setpoints ${}^W X^G(t)$ in the end-effector space, which gives us a nominal trajectory to reach and open the cupboard. \"Nominal\" refers to an ideal or baseline quantity. If you open the meshcat link from the cell above, and then run the cell below, you will be able to visualize the trajectory. This trajectory was computed by dividing the motion into following segments:\n",
    "\n",
    "- $0 \\leq t \\leq 5$: The end-effector linearly interpolates between the initial pose at $t=0$, and the grasp pose required to grip the cylinder (${}^W\\mathbf{X}^H$ at $t=5$), while having the gripper open.\n",
    "- $5 \\leq t \\leq 6$: The end-effector stays still at ${}^W\\mathbf{X}^H$, and the gripper is closed.\n",
    "- $6 \\leq t \\leq 11$: The end-effector follows an arc of the handle as the door opens. The gripper remains closed.\n",
    "\n",
    "In this notebook, you will convert this end effector trajectory to a joint-space trajectory using optimization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "3d12cdc1c144470498445b8da094289e",
    "deepnote_cell_type": "code",
    "execution_context_id": "8121b1bb-b4b2-4c8d-b0a7-a27c6d98adad",
    "execution_millis": 15,
    "execution_start": 1759156526563,
    "source_hash": "97f2e6a"
   },
   "outputs": [],
   "source": [
    "def setup_manipulation_station() -> RigidTransform:\n",
    "    builder = DiagramBuilder()\n",
    "    scenario = LoadScenario(filename=FindResource(\"models/cupboard.scenario.yaml\"))\n",
    "    station = builder.AddSystem(MakeHardwareStation(scenario, meshcat))\n",
    "    plant = station.GetSubsystemByName(\"plant\")\n",
    "    scene_graph = station.GetSubsystemByName(\"scene_graph\")\n",
    "    AddMultibodyTriad(plant.GetFrameByName(\"body\"), scene_graph)\n",
    "\n",
    "    iiwa_position = builder.AddSystem(ConstantVectorSource(np.zeros(7)))\n",
    "    builder.Connect(\n",
    "        iiwa_position.get_output_port(), station.GetInputPort(\"iiwa.position\")\n",
    "    )\n",
    "\n",
    "    wsg_position = builder.AddSystem(ConstantVectorSource([0.06]))\n",
    "    builder.Connect(\n",
    "        wsg_position.get_output_port(), station.GetInputPort(\"wsg.position\")\n",
    "    )\n",
    "\n",
    "    diagram = builder.Build()\n",
    "\n",
    "    context = plant.CreateDefaultContext()\n",
    "    gripper = plant.GetBodyByName(\"body\")\n",
    "\n",
    "    initial_pose = plant.EvalBodyPoseInWorld(context, gripper)\n",
    "\n",
    "    simulator = Simulator(diagram)\n",
    "    simulator.set_target_realtime_rate(1.0)\n",
    "    simulator.AdvanceTo(0.01)\n",
    "\n",
    "    return initial_pose\n",
    "\n",
    "\n",
    "# Get initial pose of the gripper by using default context of manip station.\n",
    "initial_pose = setup_manipulation_station()\n",
    "\n",
    "p_WR = np.array([0.7477, -0.1445, 0.4148])  # frame R: center of left door.\n",
    "\n",
    "p_Rhandle = np.array([-0.033, 0.1245, 0])  # handle: frame attached to right handle.\n",
    "p_Whandle = p_WR + p_Rhandle\n",
    "\n",
    "p_Rhinge = np.array([0.008, -0.1395, 0])  # hinge: frame attached to right hinge.\n",
    "p_Whinge = p_WR + p_Rhinge\n",
    "\n",
    "p_Rhinge_handle = p_Rhandle - p_Rhinge\n",
    "r_Rhinge_handle = np.linalg.norm(\n",
    "    p_Rhandle - p_Rhinge\n",
    ")  # distance between handle and hinge.\n",
    "\n",
    "theta_Rhinge_handle = np.arctan2(p_Rhinge_handle[1], p_Rhinge_handle[0])\n",
    "angle_end = np.pi  # end of angle. Decrease to 120~160 deg for the easy version.\n",
    "\n",
    "\n",
    "# Interpolate pose for opening doors.\n",
    "def InterpolatePoseOpen(t: float) -> RigidTransform:\n",
    "    # Start by interpolating the yaw angle of the hinge.\n",
    "    angle_start = theta_Rhinge_handle\n",
    "    theta = angle_start + (angle_end - angle_start) * t\n",
    "    # Convert to position and rotation.\n",
    "    p_Whandle = r_Rhinge_handle * np.array([np.cos(theta), np.sin(theta), 0]) + p_Whinge\n",
    "    # Add some offset here to account for gripper yaw angle.\n",
    "    R_Whandle = RollPitchYaw(0, 0, theta).ToRotationMatrix()\n",
    "    X_Whandle = RigidTransform(R_Whandle, p_Whandle)\n",
    "\n",
    "    # Add a little offset to account for gripper.\n",
    "    p_handleG = np.array([0.0, 0.1, 0.0])\n",
    "    R_handleG = RollPitchYaw(0, np.pi, np.pi).ToRotationMatrix()\n",
    "    X_handleG = RigidTransform(R_handleG, p_handleG)\n",
    "    X_WG = X_Whandle.multiply(X_handleG)\n",
    "    return X_WG\n",
    "\n",
    "\n",
    "## Interpolate Pose for entry.\n",
    "def make_gripper_orientation_trajectory() -> PiecewiseQuaternionSlerp:\n",
    "    traj = PiecewiseQuaternionSlerp()\n",
    "    traj.Append(0.0, initial_pose.rotation())\n",
    "    traj.Append(5.0, InterpolatePoseOpen(0.0).rotation())\n",
    "    return traj\n",
    "\n",
    "\n",
    "def make_gripper_position_trajectory() -> PiecewisePolynomial:\n",
    "    traj = PiecewisePolynomial.FirstOrderHold(\n",
    "        [0.0, 5.0],\n",
    "        np.vstack(\n",
    "            [\n",
    "                [initial_pose.translation()],\n",
    "                [InterpolatePoseOpen(0.0).translation()],\n",
    "            ]\n",
    "        ).T,\n",
    "    )\n",
    "    return traj\n",
    "\n",
    "\n",
    "entry_traj_rotation = make_gripper_orientation_trajectory()\n",
    "entry_traj_translation = make_gripper_position_trajectory()\n",
    "\n",
    "\n",
    "def InterpolatePoseEntry(t: float) -> RigidTransform:\n",
    "    return RigidTransform(\n",
    "        RotationMatrix(entry_traj_rotation.orientation(t)),\n",
    "        entry_traj_translation.value(t),\n",
    "    )\n",
    "\n",
    "\n",
    "# Wrapper function for end-effector pose. Total time: 11 seconds.\n",
    "def InterpolatePose(t: float) -> RigidTransform:\n",
    "    if t < 5.0:\n",
    "        # Duration of entry motion is set to 5 seconds.\n",
    "        return InterpolatePoseEntry(t)\n",
    "    elif (t >= 5.0) and (t < 6.0):\n",
    "        # Wait for a second to grip the handle.\n",
    "        return InterpolatePoseEntry(5.0)\n",
    "    else:\n",
    "        # Duration of the open motion is set to 5 seconds.\n",
    "        return InterpolatePoseOpen((t - 6.0) / 5.0)\n",
    "\n",
    "\n",
    "# Visualize our end-effector nominal trajectory.\n",
    "t_lst = np.linspace(0, 11, 30)\n",
    "pose_lst = []\n",
    "for t in t_lst:\n",
    "    AddMeshcatTriad(meshcat, path=str(t), X_PT=InterpolatePose(t), opacity=0.2)\n",
    "    pose_lst.append(InterpolatePose(t))\n",
    "\n",
    "# Create gripper trajectory.\n",
    "gripper_t_lst = np.array([0.0, 5.0, 6.0, 11.0])\n",
    "gripper_knots = np.array([0.02, 0.02, 0.0, 0.0]).reshape(1, 4)\n",
    "g_traj = PiecewisePolynomial.FirstOrderHold(gripper_t_lst, gripper_knots)\n",
    "\n",
    "\n",
    "def CreateIiwaControllerPlant() -> tuple[MultibodyPlant, list[int]]:\n",
    "    \"\"\"creates plant that includes only the robot and gripper, used for controllers.\"\"\"\n",
    "    scenario = LoadScenario(filename=FindResource(\"models/cupboard.scenario.yaml\"))\n",
    "    plant_robot = MakeMultibodyPlant(\n",
    "        scenario=scenario, model_instance_names=[\"iiwa\", \"wsg\"]\n",
    "    )\n",
    "\n",
    "    link_frame_indices = []\n",
    "    for i in range(8):\n",
    "        link_frame_indices.append(\n",
    "            plant_robot.GetFrameByName(\"iiwa_link_\" + str(i)).index()\n",
    "        )\n",
    "\n",
    "    return plant_robot, link_frame_indices\n",
    "\n",
    "\n",
    "def BuildAndSimulateTrajectory(\n",
    "    q_traj: Trajectory, g_traj: Trajectory, duration: float = 0.01\n",
    ") -> tuple[Simulator, MultibodyPlant]:\n",
    "    \"\"\"Simulate trajectory for manipulation station.\n",
    "    @param q_traj: Trajectory class used to initialize TrajectorySource for joints.\n",
    "    @param g_traj: Trajectory class used to initialize TrajectorySource for gripper.\n",
    "    \"\"\"\n",
    "    builder = DiagramBuilder()\n",
    "    scenario = LoadScenario(filename=FindResource(\"models/cupboard.scenario.yaml\"))\n",
    "    station = builder.AddSystem(MakeHardwareStation(scenario, meshcat))\n",
    "    plant = station.GetSubsystemByName(\"plant\")\n",
    "    scene_graph = station.GetSubsystemByName(\"scene_graph\")\n",
    "    AddMultibodyTriad(plant.GetFrameByName(\"body\"), scene_graph)\n",
    "\n",
    "    q_traj_system = builder.AddSystem(TrajectorySource(q_traj))\n",
    "    g_traj_system = builder.AddSystem(TrajectorySource(g_traj))\n",
    "\n",
    "    builder.Connect(\n",
    "        q_traj_system.get_output_port(), station.GetInputPort(\"iiwa.position\")\n",
    "    )\n",
    "    builder.Connect(\n",
    "        g_traj_system.get_output_port(), station.GetInputPort(\"wsg.position\")\n",
    "    )\n",
    "\n",
    "    diagram = builder.Build()\n",
    "\n",
    "    simulator = Simulator(diagram)\n",
    "    meshcat.StartRecording(set_visualizations_while_recording=False)\n",
    "    simulator.AdvanceTo(duration)\n",
    "    meshcat.PublishRecording()\n",
    "\n",
    "    return simulator, plant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ac233113ef0049fa9336739e2b2382e8",
    "deepnote_cell_type": "markdown",
    "id": "Rv46nnqnqTnq"
   },
   "source": [
    "## Part 2: Thought Exercise - Can we Relax Constraints?\n",
    "\n",
    "For this thought exercise, we will be focusing on just our grasping pose keyframe, and disregarding the rest of the trajectory. We define $H$ as the frame the center of the handle, which we can observe in the diagram below. We will denote our decision variables as $q$ (joint angles of the arm), and the forward dynamics function as\n",
    "\n",
    "$${}^W\\mathbf{X}^G = f(q)$$\n",
    "\n",
    "(You may access the rotation and translation parts independently with ${}^W\\mathbf{R}^G=f_R(q)$ and ${}^Wp^G=f_p(q)$). \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/RussTedrake/manipulation/master/book/figures/exercises/door.png\" width=\"700\">\n",
    "\n",
    "Recall one of the main ideas from the lecture: instead of having ${}^W\\mathbf{X}^G=f(q)$ be constrained to exactly ${}^W\\mathbf{X}^H$, the inverse kinematics problem can benefit a lot by allowing a set of ${}^W\\mathbf{X}^G$ which makes sense for our problem.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e487f03355d343e08db0cfec1ee4b562",
    "deepnote_cell_type": "markdown",
    "id": "d9lJdeBZEKie"
   },
   "source": [
    "### Gradescope Verification 1\n",
    "**Question:** Let us parametrize $${}^H X ^G$$ with six degrees of freedom: xyz positions and roll-pitch-yaw rotation (i.e. rotations around the xyz axii, respectively) of frame $G$ with respect to frame $H$. Which three should we constrain to be exactly equal, and which three should willing to provide some slack? For this, let's ignore the length of the grippers. In Gradescope, select the three which we should constraint to be **exactly equal**:\n",
    "\n",
    "A. x position \n",
    "B. y position \n",
    "C. z position \n",
    "D. x orientation (roll) \n",
    "E. y orientation (pitch) \n",
    "F. z orientation (yaw) \n",
    "\n",
    "(HINT: You should constrain two positions and one orientation. Remember we are ignoring the length of the grippers. Also remember the x-y-z axes are represented in red-green-blue colors respectively.)\n",
    "\n",
    "Now, for the purposes of our problem, we want to enforce equality constraints (up to a small tolerance) on both the position and the orientation. This is because we will be solving IK along an entire trajectory, not just for the grasp pose. That said, in other contexts we might choose to introduce slack or relaxations to improve feasibility.\n",
    "\n",
    "We can write our final optimization along the entire trajectory. For each pose $I$, we solve:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\min_q \\quad & \\lVert q - q_{nom} \\rVert^2 \\\\\n",
    "\\text{s.t.} \\quad & f_p(q) = {}^W p^I \\\\\n",
    "& f_R(q) = {}^W R^I\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "### Gradescope Verification 2\n",
    "**Question:** Recall that $q_{nom}$ are the baseline joint angles we define (and update) throughout our the optimization. What is the purpose of the quadratic cost term in our optimization formulation? Select all that apply\n",
    "\n",
    "A. To bias the solver toward a preferred “natural” configuration when multiple solutions exist.\n",
    "B. To ensure joint limits are respected. \n",
    "C. To guarantee that orientation constraints are satisfied exactly. \n",
    "D. To improve numerical stability and avoid unnecessarily large joint displacements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "abb70c1afed6460694659c989fb3e09a",
    "deepnote_cell_type": "markdown",
    "id": "MwNzqhzZrzeX"
   },
   "source": [
    "## Part 3: Solving The Optimization\n",
    "\n",
    "Now it's time to implement the optimization!\n",
    "\n",
    "**YOUR TASK:** Below, you must implement `create_q_knots`, which accepts a list of key frames `pose_lst`, and converts them to joint coordinates. You will use Drake's `inverse_kinematics` package.\n",
    "\n",
    "For each keyframe $I$, you must:\n",
    "- Implement constraints on `ik` using `AddOrientationConstraint` and `AddPositionConstraint`. Note that these implement inequality constraints, which is okay if our error tolerance is small.\n",
    "- Add a joint-centering cost on `q_nominal`.\n",
    "- If `i==0`, set the initial guess to be nominal configuration using [`prog.SetInitialGuess`](https://drake.mit.edu/doxygen_cxx/classdrake_1_1solvers_1_1_mathematical_program.html#ae48cb6d2263ccf09e38932dcd27f769f). Otherwise, set the initial guess to be the solution you obtained on the previous IK problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "71f881f3cac4467e9f0e9efab99e71e8",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Before you get started, go through these exercises to get an idea of how to implement the constraints in Drake's [InverseKinematics]() class.\n",
    "\n",
    "### Gradescope Verification 3\n",
    "Read the documentation for the [AddOrientationConstraint](https://drake.mit.edu/doxygen_cxx/classdrake_1_1multibody_1_1_inverse_kinematics.html#a693b3a9627e08ae92d2978b4ca516b3c) Method in Drake to answer the following questions. Note that AddOrientationConstraint implements an inequality constraint, which is okay for this problem if we set the theta bound to be small.\n",
    "\n",
    "**Question:** What are frames $\\bar{A}$ and $\\bar{B}$? Select all that apply.\n",
    "\n",
    "A. Arbitrary \"virtual\" frames that do not need to exist in the plant \n",
    "B. Frames existing in the MultibodyPlant \n",
    "C. Task frames constrained to have angle difference $\\theta \\leq \\theta_{bound}$ \n",
    "D. Reference frames such that $^{\\bar{A}}R^A$ and $^{\\bar{B}}R^B$ are constant throughout the optimization \n",
    "E. Reference frames such that $^{\\bar{A}}R^A$ and $^{\\bar{B}}R^B$ may change throughout the optimization\n",
    "\n",
    "**Question:** What is the purpose of frames $\\bar{A}$ and $\\bar{B}$? Select all that apply.\n",
    "\n",
    "A. They are the frames which we wish to align \n",
    "B. Use existing frames in the MultibodyPlant to express the task frames $A$ and $B$ in \n",
    "C. Allow you to define orientation constraints on arbitrary axes that are rigidly attached to bodies \n",
    "D. Ensure that you only give the orientation of $A$ and $B$ relative to the world and gripper, respectively \n",
    "\n",
    "### Gradescope Verification 4\n",
    "Read the documentation for the [AddPositionConstraint](https://drake.mit.edu/doxygen_cxx/classdrake_1_1multibody_1_1_inverse_kinematics.html#a7c669013ee2890d3a8c457668541cdba) Method in Drake to answer the following questions:\n",
    "\n",
    "**Question:** Which of the following are true about the point $Q$? Select all that apply.\n",
    "\n",
    "A. It is a point fixed relative to frame B \n",
    "B. It is an arbitrary free-floating point in space \n",
    "C. It changes position relative to frame B during optimization \n",
    "D. We aim to constrain its position in frame A \n",
    "\n",
    "**Question:** What does the constraint enforce?\n",
    "\n",
    "A. That the coordinates of Q, expressed in frame B, remain between ${}^A p ^{Q\\_lower}$ and ${}^A p ^{Q\\_upper}$ \n",
    "B. That the distance between A and B is fixed \n",
    "D. That the coordinates of Q, expressed in frame A, remain between ${}^A p ^{Q\\_lower}$ and ${}^A p ^{Q\\_upper}$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d94811eb250f4be18428c3c35c271171",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Now you're ready! Complete the `create_q_knots` function below.\n",
    "\n",
    "**Note:** \n",
    "When we define our constraints, we want to enfore the following tolerances\n",
    "- Our position tolerance should be such that end effector matches the desired pose to within 1mm translation along each axis\n",
    "- Our orientation tolerance should be such that the rotation should is off by no more than 0.01*np.pi radians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "e3cd81011afc4cfc9d1c7a03f2770370",
    "deepnote_cell_type": "code",
    "execution_context_id": "427dc2e2-a818-4650-9a24-3948c3c75cc7",
    "execution_millis": 0,
    "execution_start": 1758829731194,
    "id": "d9b_FojtUQoP",
    "source_hash": "19ca4dfd"
   },
   "outputs": [],
   "source": [
    "def create_q_knots(pose_lst: list[RigidTransform]) -> np.ndarray:\n",
    "    \"\"\"Convert end-effector pose list to joint position list using series of\n",
    "    InverseKinematics problems. Note that q is 9-dimensional because the last 2 dimensions\n",
    "    contain gripper joints, but these should not matter to the constraints.\n",
    "    @param: pose_lst list[RigidTransform]: post_lst[i] contains keyframe X_WG at index i.\n",
    "    @return: q_knots np.ndarray: q_knots[i] contains IK solution that will give f(q_knots[i]) \\approx pose_lst[i].\n",
    "    \"\"\"\n",
    "    q_knots = []\n",
    "    plant, _ = CreateIiwaControllerPlant()\n",
    "    world_frame = plant.world_frame()\n",
    "    gripper_frame = plant.GetFrameByName(\"body\")\n",
    "    q_nominal = np.array(\n",
    "        [0.0, 0.6, 0.0, -1.75, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
    "    )  # nominal joint angles for joint-centering.\n",
    "\n",
    "    for i in range(len(pose_lst)):\n",
    "        ik = inverse_kinematics.InverseKinematics(plant)\n",
    "        q_variables = ik.q()  # Get variables for MathematicalProgram\n",
    "        prog = ik.prog()  # Get MathematicalProgram\n",
    "\n",
    "        ### TODO: Add your constraints, cost, and initial guess here ###\n",
    "\n",
    "        # Get the desired pose for this keyframe\n",
    "        desired_pose = pose_lst[i]\n",
    "\n",
    "        # 1. Add position constraint (1mm tolerance = 0.001m)\n",
    "        position_tolerance = 0.001\n",
    "        lower_bound = desired_pose.translation() - position_tolerance\n",
    "        upper_bound = desired_pose.translation() + position_tolerance\n",
    "\n",
    "        print(f\"{lower_bound=}\")\n",
    "        print(f\"{upper_bound=}\")\n",
    "\n",
    "        ik.AddPositionConstraint(\n",
    "            frameB=gripper_frame,\n",
    "            p_BQ=np.array([0, 0, 0]),  # Point Q at origin of gripper frame\n",
    "            frameA=world_frame,\n",
    "            p_AQ_lower=lower_bound,\n",
    "            p_AQ_upper=upper_bound\n",
    "        )\n",
    "\n",
    "        # 2. Add orientation constraint (0.01*pi radians tolerance)\n",
    "        orientation_tolerance = 0.01 * np.pi\n",
    "\n",
    "        ik.AddOrientationConstraint(\n",
    "            frameAbar=world_frame,\n",
    "            R_AbarA=desired_pose.rotation(),\n",
    "            frameBbar=gripper_frame, \n",
    "            R_BbarB=RotationMatrix.Identity(),\n",
    "            theta_bound=orientation_tolerance\n",
    "        )\n",
    "\n",
    "        # 3. Add joint-centering cost\n",
    "        prog.AddQuadraticErrorCost(\n",
    "            Q=np.eye(len(q_variables)),\n",
    "            x_desired=q_nominal,\n",
    "            vars=q_variables\n",
    "        )\n",
    "\n",
    "        # 4. Set initial guess\n",
    "        if i == 0:\n",
    "            # Use nominal configuration for first pose\n",
    "            prog.SetInitialGuess(q_variables, q_nominal)\n",
    "        else:\n",
    "            # Use previous solution as initial guess\n",
    "            prog.SetInitialGuess(q_variables, q_knots[i-1])\n",
    "\n",
    "        ################################################\n",
    "\n",
    "        result = Solve(prog)\n",
    "\n",
    "        assert result.is_success()\n",
    "\n",
    "        q_knots.append(result.GetSolution(q_variables))\n",
    "\n",
    "    return q_knots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "74a4530b82b643aa8b4936ab5e7cafcd",
    "deepnote_cell_type": "markdown",
    "id": "vZKbWWLNqxMH"
   },
   "source": [
    "When you have implemented your function, you can run the cell below to initialize your simulation. Once everything loads up in Meshcat, run the next cell to run the full simulation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "90601c0fae3b4662b9095c7cbccfb5f6",
    "deepnote_cell_type": "code",
    "execution_context_id": "427dc2e2-a818-4650-9a24-3948c3c75cc7",
    "execution_millis": 13510,
    "execution_start": 1758829731339,
    "id": "tXpo5zh4PMqB",
    "source_hash": "87a07321"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower_bound=array([ 0.46856584, -0.001     ,  0.19819636])\n",
      "upper_bound=array([0.47056584, 0.001     , 0.20019636])\n",
      "lower_bound=array([ 0.47966588, -0.00368145,  0.2145525 ])\n",
      "upper_bound=array([ 0.48166588, -0.00168145,  0.2165525 ])\n",
      "lower_bound=array([ 0.49076592, -0.00636289,  0.23090863])\n",
      "upper_bound=array([ 0.49276592, -0.00436289,  0.23290863])\n",
      "lower_bound=array([ 0.50186596, -0.00904434,  0.24726477])\n",
      "upper_bound=array([ 0.50386596, -0.00704434,  0.24926477])\n",
      "lower_bound=array([ 0.512966  , -0.01172578,  0.26362091])\n",
      "upper_bound=array([ 0.514966  , -0.00972578,  0.26562091])\n",
      "lower_bound=array([ 0.52406605, -0.01440723,  0.27997705])\n",
      "upper_bound=array([ 0.52606605, -0.01240723,  0.28197705])\n",
      "lower_bound=array([ 0.53516609, -0.01708868,  0.29633319])\n",
      "upper_bound=array([ 0.53716609, -0.01508868,  0.29833319])\n",
      "lower_bound=array([ 0.54626613, -0.01977012,  0.31268933])\n",
      "upper_bound=array([ 0.54826613, -0.01777012,  0.31468933])\n",
      "lower_bound=array([ 0.55736617, -0.02245157,  0.32904546])\n",
      "upper_bound=array([ 0.55936617, -0.02045157,  0.33104546])\n",
      "lower_bound=array([ 0.56846621, -0.02513302,  0.3454016 ])\n",
      "upper_bound=array([ 0.57046621, -0.02313302,  0.3474016 ])\n",
      "lower_bound=array([ 0.57956625, -0.02781446,  0.36175774])\n",
      "upper_bound=array([ 0.58156625, -0.02581446,  0.36375774])\n",
      "lower_bound=array([ 0.59066629, -0.03049591,  0.37811388])\n",
      "upper_bound=array([ 0.59266629, -0.02849591,  0.38011388])\n",
      "lower_bound=array([ 0.60176634, -0.03317735,  0.39447002])\n",
      "upper_bound=array([ 0.60376634, -0.03117735,  0.39647002])\n",
      "lower_bound=array([ 0.61286638, -0.0358588 ,  0.41082616])\n",
      "upper_bound=array([ 0.61486638, -0.0338588 ,  0.41282616])\n",
      "lower_bound=array([ 0.61488457, -0.03634634,  0.4138    ])\n",
      "upper_bound=array([ 0.61688457, -0.03434634,  0.4158    ])\n",
      "lower_bound=array([ 0.61488457, -0.03634634,  0.4138    ])\n",
      "upper_bound=array([ 0.61688457, -0.03434634,  0.4158    ])\n",
      "lower_bound=array([ 0.61005262, -0.03912577,  0.4138    ])\n",
      "upper_bound=array([ 0.61205262, -0.03712577,  0.4158    ])\n",
      "lower_bound=array([ 0.58451259, -0.05606061,  0.4138    ])\n",
      "upper_bound=array([ 0.58651259, -0.05406061,  0.4158    ])\n",
      "lower_bound=array([ 0.5609365 , -0.07563738,  0.4138    ])\n",
      "upper_bound=array([ 0.5629365 , -0.07363738,  0.4158    ])\n",
      "lower_bound=array([ 0.53959642, -0.09763018,  0.4138    ])\n",
      "upper_bound=array([ 0.54159642, -0.09563018,  0.4158    ])\n",
      "lower_bound=array([ 0.52073861, -0.1217852 ,  0.4138    ])\n",
      "upper_bound=array([ 0.52273861, -0.1197852 ,  0.4158    ])\n",
      "lower_bound=array([ 0.5045807 , -0.14782371,  0.4138    ])\n",
      "upper_bound=array([ 0.5065807 , -0.14582371,  0.4158    ])\n",
      "lower_bound=array([ 0.49130913, -0.17544521,  0.4138    ])\n",
      "upper_bound=array([ 0.49330913, -0.17344521,  0.4158    ])\n",
      "lower_bound=array([ 0.48107707, -0.20433097,  0.4138    ])\n",
      "upper_bound=array([ 0.48307707, -0.20233097,  0.4158    ])\n",
      "lower_bound=array([ 0.47400259, -0.23414764,  0.4138    ])\n",
      "upper_bound=array([ 0.47600259, -0.23214764,  0.4158    ])\n",
      "lower_bound=array([ 0.47016732, -0.26455114,  0.4138    ])\n",
      "upper_bound=array([ 0.47216732, -0.26255114,  0.4158    ])\n",
      "lower_bound=array([ 0.46961554, -0.29519062,  0.4138    ])\n",
      "upper_bound=array([ 0.47161554, -0.29319062,  0.4158    ])\n",
      "lower_bound=array([ 0.47235359, -0.32571249,  0.4138    ])\n",
      "upper_bound=array([ 0.47435359, -0.32371249,  0.4158    ])\n",
      "lower_bound=array([ 0.4783499 , -0.35576455,  0.4138    ])\n",
      "upper_bound=array([ 0.4803499 , -0.35376455,  0.4158    ])\n",
      "lower_bound=array([ 0.48753526, -0.385     ,  0.4138    ])\n",
      "upper_bound=array([ 0.48953526, -0.383     ,  0.4158    ])\n"
     ]
    }
   ],
   "source": [
    "q_knots = np.array(create_q_knots(pose_lst))\n",
    "q_traj = PiecewisePolynomial.CubicShapePreserving(t_lst, q_knots[:, 0:7].T)\n",
    "simulator, station_plant = BuildAndSimulateTrajectory(q_traj, g_traj, 11.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e5abf999053741b79f25b31e1023aef9",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "You should now see the robot following the trajectory to open the door! You can also check the correctness of your implementation with the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.2017523431146981\n",
      "1.3960299011153543\n",
      "1.3571473351263394\n",
      "-0.6645037854668043\n",
      "-2.8583349125041493\n",
      "-2.0944\n",
      "1.5811790614611612\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(map(str, q_knots[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "36ee896c4e0f409ebcd04b67d221dd8f",
    "deepnote_cell_type": "code",
    "execution_context_id": "427dc2e2-a818-4650-9a24-3948c3c75cc7",
    "execution_millis": 505,
    "execution_start": 1758829789554,
    "source_hash": "5367a7e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score is 5/5.\n",
      "\n",
      "Score for Test 40 degree bound for door angle is 2/2.\n",
      "\n",
      "Score for Test 70 degree bound for door angle is 1/1.\n",
      "\n",
      "Score for Test 10 degree bound for door angle is 2/2.\n"
     ]
    }
   ],
   "source": [
    "from manipulation.exercises.grader import Grader\n",
    "from manipulation.exercises.trajectories.test_door_opening import TestDoorOpening\n",
    "\n",
    "Grader.grade_output([TestDoorOpening], [locals()], \"results.json\")\n",
    "Grader.print_test_results(\"results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "27e06de107a44acf87565ffef30a3180",
    "deepnote_cell_type": "markdown",
    "id": "MwE8yNg58VQN"
   },
   "source": [
    "### Gradescope Verification 5\n",
    "\n",
    "Now that you have the list of optimal joint angles at each pose for opening the door, verify your implementation in Gradescope.\n",
    "\n",
    "**Question:** In gradescope, enter the optimal joint angles for the final pose in the trajectory. Please give your answers to 4 decimal places. Recall that the last 2 dimensions of q are the gripper joints, so we can ignore those.\n",
    "\n",
    "**Note:** Be sure you are using the proper tolerances for the orientation and position constraints. The constraints must be precise for the verification."
   ]
  }
 ],
 "metadata": {
  "deepnote_notebook_id": "06eb4f162a3248e082b0560fe143a27c",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": "4",
 "nbformat_minor": "0"
}
