{"cells":[{"cellId":"21d11331cd0348caaf9ade0fcd74d103","cell_type":"markdown","metadata":{"cell_id":"21d11331cd0348caaf9ade0fcd74d103","deepnote_cell_type":"markdown"},"source":"# Sampling-Based Motion Planning: RRT and RRT-Connect\n\nImpressively, we made it through previous chapters without doing any real motion planning! We were able to get away with explicitly defining poses of interest and interpolating between them without any consideration of our environment. Unfortunately, with this approach, navigating cluttered environments while avoiding both collisions and system limitations is quite the challenge. To address this, we'll use motion planning\n\nIn this exercise, you'll build your first sampling-based motion planners. We'll start with the famous Rapidly-exploring Random Tree (RRT) algorithm. Next, we will extend it to the popular two-tree variant, RRT-Connect.\n\n**Learning Objectives:**\n1. Implement RRT: nearest-neighbor search, steering via intermediate configurations, collision checking along edges, and goal biasing.\n2. Implement RRT-Connect: grow two trees (start/goal), alternate extend/connect steps, and splice paths when the trees meet.\n3. Compare planners using simple metrics (iterations to solve), and reason about parameter choices (step size, goal bias).\n\n**What you'll build:**\n- A collision-free configuration-space path for the IIWA in a Drake simulation.\n\n**Reference (optional):**\n- [Kuffner & LaValle, “RRT-Connect: An Efficient Approach to Single-Query Path Planning” (ICRA 2000)](https://www.cs.cmu.edu/afs/cs/academic/class/15494-s12/readings/kuffner_icra2000.pdf).\n\n\nLet's start by getting our imports set up and launching Meshcat.\n","block_group":"2a5dfe353c0c42e49ca3369b6587d4a5"},{"cellId":"013af3abf4d74b7a9dba607c1d09c9c9","cell_type":"code","metadata":{"id":"TCHw6F7Vw9Q_","source_hash":"d7ead2a9","execution_start":1759198720401,"execution_millis":2881,"execution_context_id":"9a288765-7619-4b0f-b9a7-5404c8ffeff1","cell_id":"013af3abf4d74b7a9dba607c1d09c9c9","deepnote_cell_type":"code"},"source":"import time\nfrom random import random\nfrom typing import Literal\n\nimport numpy as np\nfrom pydrake.all import (\n    ConstantVectorSource,\n    DiagramBuilder,\n    MultibodyPlant,\n    Parser,\n    RigidTransform,\n    RollPitchYaw,\n    RotationMatrix,\n    Simulator,\n    SolutionResult,\n    Solve,\n    StartMeshcat,\n    TrajectorySource,\n)\nfrom pydrake.multibody import inverse_kinematics\nfrom pydrake.trajectories import PiecewisePolynomial\n\nfrom manipulation import running_as_notebook\nfrom manipulation.exercises.trajectories.rrt_planner.robot import (\n    ConfigurationSpace,\n    Range,\n)\nfrom manipulation.exercises.trajectories.rrt_planner.rrt_planning import (\n    RRT,\n    Problem,\n    TreeNode,\n)\nfrom manipulation.meshcat_utils import AddMeshcatTriad\nfrom manipulation.station import LoadScenario, MakeHardwareStation","block_group":"c0a7701b17e04a77a2bf76c360e6b8f0","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"30abff5d47414390954376bbfed1c79a","cell_type":"code","metadata":{"source_hash":"6d42057f","execution_start":1759198723334,"execution_millis":88,"execution_context_id":"9a288765-7619-4b0f-b9a7-5404c8ffeff1","cell_id":"30abff5d47414390954376bbfed1c79a","deepnote_cell_type":"code"},"source":"# Start the visualizer.\nmeshcat = StartMeshcat()","block_group":"0bc8c6ab27ee4a2b978eeea0cccfc618","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"efd78701099443f790b661d1b80f7d1b","cell_type":"markdown","metadata":{"cell_id":"efd78701099443f790b661d1b80f7d1b","deepnote_cell_type":"markdown"},"source":"### 2D visualization of the RRT algorithm\n\nRun the cell below to get a glimpse of the RRT algorithm in action","block_group":"7b4d690510674e3ea8cd981bb2e80666"},{"cellId":"d624ce964f0c40379e0c694572d9ff95","cell_type":"code","metadata":{"source_hash":"646c7e82","execution_start":1759198736269,"execution_millis":1,"execution_context_id":"9a288765-7619-4b0f-b9a7-5404c8ffeff1","cell_id":"d624ce964f0c40379e0c694572d9ff95","deepnote_cell_type":"code"},"source":"from IPython.display import Image\n\nImage(\n    url=\"https://upload.wikimedia.org/wikipedia/commons/thumb/6/62/Rapidly-exploring_Random_Tree_%28RRT%29_500x373.gif/450px-Rapidly-exploring_Random_Tree_%28RRT%29_500x373.gif\"\n)","block_group":"5d022d04ac684bcb975e4fd0d58c8ee5","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"f83520175bdd476b88e4e4b4818ed173","cell_type":"markdown","metadata":{"cell_id":"f83520175bdd476b88e4e4b4818ed173","deepnote_cell_type":"markdown"},"source":"### Add Scenario\nRun the cell below to add the scenario that will be used throughout this notebook.","block_group":"3ec5776451994b4ba6ed9960699c6ff5"},{"cellId":"91e423d315724b719172157fabf013f4","cell_type":"code","metadata":{"source_hash":"8df1ddb7","execution_start":1759200330795,"execution_millis":354,"execution_context_id":"9a288765-7619-4b0f-b9a7-5404c8ffeff1","cell_id":"91e423d315724b719172157fabf013f4","deepnote_cell_type":"code"},"source":"scenario_yaml = f\"\"\"directives:\n- add_model:\n    name: iiwa\n    file: package://drake_models/iiwa_description/sdf/iiwa7_no_collision.sdf\n    default_joint_positions:\n        iiwa_joint_1: [0]\n        iiwa_joint_2: [0.5]\n        iiwa_joint_3: [0]\n        iiwa_joint_4: [-1.9]\n        iiwa_joint_5: [0]\n        iiwa_joint_6: [0.65]\n        iiwa_joint_7: [1.7]\n- add_weld:\n    parent: world\n    child: iiwa::iiwa_link_0\n    X_PC:\n        translation: [-0.25, 0, 0]\n- add_model:\n    name: wsg\n    file: package://manipulation/hydro/schunk_wsg_50_with_tip.sdf\n- add_weld:\n    parent: iiwa::iiwa_link_7\n    child: wsg::body\n    X_PC:\n        translation: [0, 0, 0.114]\n        rotation: !Rpy {{ deg: [90, 0, 90]}}\n- add_model:\n    name: table\n    file: package://drake_models/manipulation_station/amazon_table_simplified.sdf\n- add_weld:\n    parent: world\n    child: table::amazon_table\n    X_PC:\n        translation: [0.3257, 0, -0.0127]\n- add_model:\n    name: cupboard\n    file: package://manipulation/hydro/cupboard.sdf\n- add_weld:\n    parent: world\n    child: cupboard::cupboard_body\n    X_PC:\n        translation: [0.9057, 0, 0.4148]\n        rotation: !Rpy {{ deg: [0, 0, 180]}}\n- add_model:\n    name: camera0\n    file: package://manipulation/camera_box.sdf\n- add_weld:\n    parent: world\n    child: camera0::base\n    X_PC:\n        translation: [-0.228895, -0.452176, 0.486308]\n        rotation: !Rpy {{ deg: [146.0, 78.0, 170]}}\n- add_model:\n    name: camera1\n    file: package://manipulation/camera_box.sdf\n- add_weld:\n    parent: world\n    child: camera1::base\n    X_PC:\n        translation: [-0.201813, 0.469259, 0.417045]\n        rotation: !Rpy {{ deg: [150.0, -76.6, -9.8]}}\n- add_model:\n    name: camera2\n    file: package://manipulation/camera_box.sdf\n- add_weld:\n    parent: world\n    child: camera2::base\n    X_PC:\n        translation: [0.786258, -0.048422, 1.043315]\n        rotation: !Rpy {{ deg: [150.0, 1.3, 88]}}\n- add_model:\n    name: bin\n    file: package://manipulation/hydro/bin.sdf\n- add_weld:\n    parent: world\n    child: bin::bin_base\n    X_PC:\n        translation: [0.2, 0, 0]\n        rotation: !Rpy {{deg: [0, 0, 180]}}\n- add_model:\n    name: mustard\n    file: package://manipulation/hydro/006_mustard_bottle.sdf\n    default_free_body_pose:\n        base_link_mustard:\n            base_frame: world\n            translation: [0.43, 0, 0.215]\nmodel_drivers:\n    iiwa: !IiwaDriver\n      control_mode: position_only\n      hand_model_name: wsg\n    wsg: !SchunkWsgDriver {{}}\n\"\"\"\n\nwith open(\"cupboard_scenario_mustard.yaml\", \"w\") as f:\n    f.write(scenario_yaml)","block_group":"612ae7f655494579828282213811deba","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"b32d9dc5558740858b73679421676640","cell_type":"markdown","metadata":{"cell_id":"b32d9dc5558740858b73679421676640","deepnote_cell_type":"markdown"},"source":"## Provided Utility Classes\n\nImplementing RRT from scratch can be very time-consuming. Below, we have provided you the important features you will need to implement the RRT algorithm. Note that in `RRT_tools`, a robot configuration is referred to as $q$, whereas a node in the RRT tree is referred to as a node. One can access the configuration of a node by \n```\nq_sample = node.value\n```","block_group":"05497ba5e67a40ffbadfcd530b6aa48a"},{"cellId":"88ca8f1fb22a45dc9b1f3f35e20d90da","cell_type":"code","metadata":{"source_hash":"4a0d3fc","execution_start":1759200334601,"execution_millis":37,"execution_context_id":"9a288765-7619-4b0f-b9a7-5404c8ffeff1","cell_id":"88ca8f1fb22a45dc9b1f3f35e20d90da","deepnote_cell_type":"code"},"source":"class ManipulationStationSim:\n    def __init__(self, is_visualizing: bool = False) -> None:\n        builder = DiagramBuilder()\n        scenario = LoadScenario(filename=\"cupboard_scenario_mustard.yaml\")\n        self.station = builder.AddSystem(\n            MakeHardwareStation(scenario, meshcat=meshcat if is_visualizing else None)\n        )\n        self.plant = self.station.GetSubsystemByName(\"plant\")\n        self.scene_graph = self.station.GetSubsystemByName(\"scene_graph\")\n        self.is_visualizing = is_visualizing\n\n        # scene graph query output port.\n        self.query_output_port = self.scene_graph.GetOutputPort(\"query\")\n\n        self.diagram = builder.Build()\n\n        # contexts\n        self.context_diagram = self.diagram.CreateDefaultContext()\n        self.context_station = self.diagram.GetSubsystemContext(\n            self.station, self.context_diagram\n        )\n        self.station.GetInputPort(\"iiwa.position\").FixValue(\n            self.context_station, np.zeros(7)\n        )\n        self.station.GetInputPort(\"wsg.position\").FixValue(self.context_station, [0.1])\n        self.context_scene_graph = self.station.GetSubsystemContext(\n            self.scene_graph, self.context_station\n        )\n        self.context_plant = self.station.GetMutableSubsystemContext(\n            self.plant, self.context_station\n        )\n        # mark initial configuration\n        self.q0 = self.plant.GetPositions(\n            self.context_plant, self.plant.GetModelInstanceByName(\"iiwa\")\n        )\n        if is_visualizing:\n            self.DrawStation(self.q0, 0.1, -np.pi / 2, np.pi / 2)\n\n    def SetStationConfiguration(\n        self,\n        q_iiwa: np.ndarray,\n        gripper_setpoint: float,\n        left_door_angle: float,\n        right_door_angle: float,\n    ) -> None:\n        \"\"\"\n        :param q_iiwa: (7,) numpy array, joint angle of robots in radian.\n        :param gripper_setpoint: float, gripper opening distance in meters.\n        :param left_door_angle: float, left door hinge angle, in [0, pi/2].\n        :param right_door_angle: float, right door hinge angle, in [0, pi/2].\n        :return:\n        \"\"\"\n        self.plant.SetPositions(\n            self.context_plant,\n            self.plant.GetModelInstanceByName(\"iiwa\"),\n            q_iiwa,\n        )\n        self.plant.SetPositions(\n            self.context_plant,\n            self.plant.GetModelInstanceByName(\"wsg\"),\n            [-gripper_setpoint / 2, gripper_setpoint / 2],\n        )\n\n        # cabinet doors\n        if left_door_angle > 0:\n            left_door_angle *= -1\n        left_hinge_joint = self.plant.GetJointByName(\"left_door_hinge\")\n        left_hinge_joint.set_angle(context=self.context_plant, angle=left_door_angle)\n\n        right_hinge_joint = self.plant.GetJointByName(\"right_door_hinge\")\n        right_hinge_joint.set_angle(context=self.context_plant, angle=right_door_angle)\n\n    def DrawStation(\n        self,\n        q_iiwa: np.ndarray,\n        gripper_setpoint: float,\n        q_door_left: float,\n        q_door_right: float,\n    ) -> None:\n        if not self.is_visualizing:\n            print(\"collision checker is not initialized with visualization.\")\n            return\n        self.SetStationConfiguration(\n            q_iiwa, gripper_setpoint, q_door_left, q_door_right\n        )\n        self.diagram.ForcedPublish(self.context_diagram)\n\n    def ExistsCollision(\n        self,\n        q_iiwa: np.ndarray,\n        gripper_setpoint: float,\n        q_door_left: float,\n        q_door_right: float,\n    ) -> bool:\n        self.SetStationConfiguration(\n            q_iiwa, gripper_setpoint, q_door_left, q_door_right\n        )\n        query_object = self.query_output_port.Eval(self.context_scene_graph)\n        collision_pairs = query_object.ComputePointPairPenetration()\n\n        return len(collision_pairs) > 0\n\n\nclass IiwaProblem(Problem):\n    def __init__(\n        self,\n        q_start: np.ndarray,\n        q_goal: np.ndarray,\n        gripper_setpoint: float,\n        left_door_angle: float,\n        right_door_angle: float,\n        is_visualizing=False,\n    ) -> None:\n        self.gripper_setpoint = gripper_setpoint\n        self.left_door_angle = left_door_angle\n        self.right_door_angle = right_door_angle\n        self.is_visualizing = is_visualizing\n\n        self.collision_checker = ManipulationStationSim(is_visualizing=is_visualizing)\n\n        # Construct configuration space for IIWA.\n        plant = self.collision_checker.plant\n        nq = 7\n        joint_limits = np.zeros((nq, 2))\n        for i in range(nq):\n            joint = plant.GetJointByName(\"iiwa_joint_%i\" % (i + 1))\n            joint_limits[i, 0] = joint.position_lower_limits().item()\n            joint_limits[i, 1] = joint.position_upper_limits().item()\n\n        range_list = []\n        for joint_limit in joint_limits:\n            range_list.append(Range(joint_limit[0], joint_limit[1]))\n\n        def l2_distance(q: tuple):\n            sum = 0\n            for q_i in q:\n                sum += q_i**2\n            return np.sqrt(sum)\n\n        max_steps = nq * [np.pi / 180]  # two degrees\n        cspace_iiwa = ConfigurationSpace(range_list, l2_distance, max_steps)\n\n        # Call base class constructor.\n        Problem.__init__(\n            self,\n            x=10,  # not used.\n            y=10,  # not used.\n            robot=None,  # not used.\n            obstacles=None,  # not used.\n            start=tuple(q_start),\n            goal=tuple(q_goal),\n            cspace=cspace_iiwa,\n        )\n\n    def collide(self, configuration: np.ndarray) -> bool:\n        q = np.array(configuration)\n        return self.collision_checker.ExistsCollision(\n            q,\n            self.gripper_setpoint,\n            self.left_door_angle,\n            self.right_door_angle,\n        )\n\n    def visualize_path(self, path: list[tuple]) -> None:\n        if path is not None:\n            # show path in meshcat\n            for q in path:\n                q = np.array(q)\n                self.collision_checker.DrawStation(\n                    q,\n                    self.gripper_setpoint,\n                    self.left_door_angle,\n                    self.right_door_angle,\n                )\n                if running_as_notebook:\n                    time.sleep(0.2)\n\n\nclass IKSolver:\n    def __init__(self) -> None:\n        ## setup controller plant\n        plant_iiwa = MultibodyPlant(0.0)\n        iiwa_file = \"package://drake_models/iiwa_description/sdf/iiwa7_no_collision.sdf\"\n        iiwa = Parser(plant_iiwa).AddModelsFromUrl(iiwa_file)[0]\n        # Define frames\n        world_frame = plant_iiwa.world_frame()\n        L0 = plant_iiwa.GetFrameByName(\"iiwa_link_0\")\n        l7_frame = plant_iiwa.GetFrameByName(\"iiwa_link_7\")\n        X_WL0 = RigidTransform([-0.25, 0, 0])\n        plant_iiwa.WeldFrames(world_frame, L0, X_WL0)\n        plant_iiwa.Finalize()\n        plant_context = plant_iiwa.CreateDefaultContext()\n\n        # gripper in link 7 frame\n        X_L7G = RigidTransform(\n            rpy=RollPitchYaw([np.pi / 2, 0, np.pi / 2]), p=[0, 0, 0.114]\n        )\n        world_frame = plant_iiwa.world_frame()\n\n        self.world_frame = world_frame\n        self.l7_frame = l7_frame\n        self.plant_iiwa = plant_iiwa\n        self.plant_context = plant_context\n        self.X_L7G = X_L7G\n\n    def solve(\n        self,\n        X_WT: RigidTransform,\n        q_guess: np.ndarray | None = None,\n        theta_bound: float = 0.01,\n        position_bound: float = 0.01,\n    ) -> tuple[np.ndarray, bool]:\n        \"\"\"\n        plant: a mini plant only consists of iiwa arm with no gripper attached\n        X_WT: transform of target frame in world frame\n        q_guess: a guess on the joint state sol\n        \"\"\"\n        plant = self.plant_iiwa\n        l7_frame = self.l7_frame\n        X_L7G = self.X_L7G\n        world_frame = self.world_frame\n\n        R_WT = X_WT.rotation()\n        p_WT = X_WT.translation()\n\n        if q_guess is None:\n            q_guess = np.zeros(7)\n\n        ik_instance = inverse_kinematics.InverseKinematics(plant)\n        # align frame A to frame B\n        ik_instance.AddOrientationConstraint(\n            frameAbar=l7_frame,\n            R_AbarA=X_L7G.rotation(),\n            #   R_AbarA=RotationMatrix(), # for link 7\n            frameBbar=world_frame,\n            R_BbarB=R_WT,\n            theta_bound=position_bound,\n        )\n        # align point Q in frame B to the bounding box in frame A\n        ik_instance.AddPositionConstraint(\n            frameB=l7_frame,\n            p_BQ=X_L7G.translation(),\n            # p_BQ=[0,0,0], # for link 7\n            frameA=world_frame,\n            p_AQ_lower=p_WT - position_bound,\n            p_AQ_upper=p_WT + position_bound,\n        )\n        prog = ik_instance.prog()\n        prog.SetInitialGuess(ik_instance.q(), q_guess)\n        result = Solve(prog)\n        if result.get_solution_result() != SolutionResult.kSolutionFound:\n            return result.GetSolution(ik_instance.q()), False\n        return result.GetSolution(ik_instance.q()), True","block_group":"309dbf5f70eb4f35b352aec67ae00633","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"63c09beb55224abfa841404a0e6b99f9","cell_type":"code","metadata":{"source_hash":"82dfb4c4","execution_start":1759200339234,"execution_millis":0,"execution_context_id":"9a288765-7619-4b0f-b9a7-5404c8ffeff1","cell_id":"63c09beb55224abfa841404a0e6b99f9","deepnote_cell_type":"code"},"source":"class RRT_tools:\n    def __init__(self, problem: IiwaProblem) -> None:\n        # rrt is a tree\n        self.rrt_tree = RRT(TreeNode(problem.start), problem.cspace)\n        problem.rrts = [self.rrt_tree]\n        self.problem = problem\n\n    def find_nearest_node_in_RRT_graph(self, q_sample: tuple) -> TreeNode:\n        nearest_node = self.rrt_tree.nearest(q_sample)\n        return nearest_node\n\n    def sample_node_in_configuration_space(self) -> tuple:\n        q_sample = self.problem.cspace.sample()\n        return q_sample\n\n    def calc_intermediate_qs_wo_collision(\n        self, q_start: tuple, q_end: tuple\n    ) -> list[tuple]:\n        \"\"\"create more samples by linear interpolation from q_start\n        to q_end. Return all samples that are not in collision\n\n        Example interpolated path:\n        q_start, qa, qb, (Obstacle), qc , q_end\n        returns >>> q_start, qa, qb\n        \"\"\"\n        return self.problem.safe_path(q_start, q_end)\n\n    def grow_rrt_tree(self, parent_node: TreeNode, q_sample: tuple) -> TreeNode:\n        \"\"\"\n        add q_sample to the rrt tree as a child of the parent node\n        returns the rrt tree node generated from q_sample\n        \"\"\"\n        child_node = self.rrt_tree.add_configuration(parent_node, q_sample)\n        return child_node\n\n    def node_reaches_goal(self, node: TreeNode, tol: float = 1e-2) -> bool:\n        \"returns true if the node is within tol of goal, false otherwise\"\n        return self.problem.cspace.distance(node.value, self.problem.goal) <= tol\n\n    def backup_path_from_node(self, node: TreeNode) -> list[tuple]:\n        path = [node.value]\n        while node.parent is not None:\n            node = node.parent\n            path.append(node.value)\n        path.reverse()\n        return path","block_group":"3bb4cd44dd124b7ab6d88c236eb9ba06","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"60ede519e04a46e29fa548c9e7381dd7","cell_type":"markdown","metadata":{"id":"YkAeqwCHydaP","cell_id":"60ede519e04a46e29fa548c9e7381dd7","deepnote_cell_type":"markdown"},"source":"## Getting Started\n\nNow that we've set up the tools we'll need to implement RRT on our iiwa, let's first generate a problem instance. Let's use the default initial joint state as our starting configuration $q_{start}$. Let's use a pre-defined frame in 3D world as our goal pose. The frame of the goal pose can be viewed in the meshcat visualizer below. ","block_group":"558e9b11e38f4f778428d5f47230bce4"},{"cellId":"c3627a46fa05448e91057e45d8d12f02","cell_type":"code","metadata":{"id":"IRzTg8bdw9RF","source_hash":"d9d9eb11","execution_start":1759200342390,"execution_millis":1557,"execution_context_id":"9a288765-7619-4b0f-b9a7-5404c8ffeff1","cell_id":"c3627a46fa05448e91057e45d8d12f02","deepnote_cell_type":"code"},"source":"env = ManipulationStationSim(True)\nq_start = env.q0\nR_WG = RotationMatrix(np.array([[0, 1, 0], [1, 0, 0], [0, 0, -1]]).T)\nT_WG_goal = RigidTransform(p=np.array([4.69565839e-01, 2.95894043e-16, 0.65]), R=R_WG)\nAddMeshcatTriad(meshcat, \"goal pose\", X_PT=T_WG_goal, opacity=0.5)","block_group":"4a02876b05c34f77bbb4bac8d21d14e5","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"0e0e458bbdc049f08291db4b1e1057fa","cell_type":"markdown","metadata":{"id":"ZHj1mtAuzP1F","cell_id":"0e0e458bbdc049f08291db4b1e1057fa","deepnote_cell_type":"markdown"},"source":"The joint states of the goal pose can be computed via inverse kinematics.","block_group":"82b60766ef2b4d00a8909a8949442285"},{"cellId":"19e24d71c6bc4ab69ad3e60cc7842b7c","cell_type":"code","metadata":{"id":"0v_4tS_xw9RL","source_hash":"a37a7473","execution_start":1759200346669,"execution_millis":11,"execution_context_id":"9a288765-7619-4b0f-b9a7-5404c8ffeff1","cell_id":"19e24d71c6bc4ab69ad3e60cc7842b7c","deepnote_cell_type":"code"},"source":"ik_solver = IKSolver()\nq_goal, optimal = ik_solver.solve(T_WG_goal, q_guess=q_start)","block_group":"e71a2cd5587d40289cb32900acd4e625","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"c262ccec77a34b7c9c66d7d7e0c1ba33","cell_type":"markdown","metadata":{"id":"_iPAypZPzgQd","cell_id":"c262ccec77a34b7c9c66d7d7e0c1ba33","deepnote_cell_type":"markdown"},"source":"Given the start and goal states, we now have sufficient information to formulate the pathfinding problem. We use `IiwaProblem` class to store all relevant information about the pathfinding problem. For this exercise, you don't have to know the details of this class.","block_group":"082ecfc7226742e39931b20801bd6432"},{"cellId":"664ef807c6bb43398c46c5a09b325b9a","cell_type":"code","metadata":{"id":"exkFjk8jw9RP","source_hash":"dc226417","execution_start":1759200348636,"execution_millis":1263,"execution_context_id":"9a288765-7619-4b0f-b9a7-5404c8ffeff1","cell_id":"664ef807c6bb43398c46c5a09b325b9a","deepnote_cell_type":"code"},"source":"gripper_setpoint = 0.1\ndoor_angle = np.pi / 2 - 0.001\nleft_door_angle = -np.pi / 2\nright_door_angle = np.pi / 2\n\niiwa_problem = IiwaProblem(\n    q_start=q_start,\n    q_goal=q_goal,\n    gripper_setpoint=gripper_setpoint,\n    left_door_angle=left_door_angle,\n    right_door_angle=right_door_angle,\n    is_visualizing=True,\n)","block_group":"360778c25b054d57841fab1d35e281ba","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"fc72abd2d54243deb3aaba6f12abfbc7","cell_type":"markdown","metadata":{"id":"njvk8Yim0AF7","cell_id":"fc72abd2d54243deb3aaba6f12abfbc7","deepnote_cell_type":"markdown"},"source":"# RRT Algorithm\n\nRRT grows a tree rooted at the starting configuration by using random samples drawn from the configuration space. At each step, a sample is drawn and a connection is made between the sample and its nearest neighbor in the tree. In the standard version of RRT, the tree extends by a fixed step in the direction of the sample if it is feasable (passes entirely through free space and obeys all constraints). Otherwise, nothing is added. Some variants, however, use different extension strategies. One such \"greedy\" variant tries to directly connect the random sample to the closest node in the tree. If the full edge is feasible, the entire edge is added to the tree. Otherwise, the longest collision-free portion of the connecting edge is added to the tree. For this problem, you are free to use either method.\n\nWith uniform sampling of the search space, the probability of expanding an existing state is proportional to the size of its Voronoi region. As the largest Voronoi regions belong to the states on the frontier of the search, this means that the tree preferentially expands towards large unsearched areas.\n\nHowever, it may be useful sometimes to bias our exploration towards the goal. In that case, one can artificially set a probability to use the goal as the next sample. \n\nThe pseudocode of the RRT algorithm is shown below.","block_group":"33b54724f3004a929544635b18bb5f2b"},{"cellId":"48877083a69240da85e890ff56e75ad4","cell_type":"markdown","metadata":{"id":"GDLn7bfYw9RT","cell_id":"48877083a69240da85e890ff56e75ad4","deepnote_cell_type":"markdown"},"source":"  **Algorithm RRT**\n    \n      Input: q_start, q_goal, max_iterations, prob_sample_goal\n      Output: path\n\n      TOOLS ← RRT TOOLS\n\n      for k = 1 to max_interation:\n        q_sample ← Generate Random Configuration\n        random number ← random()\n        if random_number < prob_sample_goal:\n            q_sample ← q_goal\n        n_near ← Find the nearest node in the tree(q_sample)\n        (q_1, q_2, ... q_N) ← Find intermediate q's from n_near to q_sample\n        \n        // iteratively add the new nodes to the tree to form a new edge\n        // for a faster runtime, it can be convenient to only add one or a few of the intermediate q's (i.e. first or last)\n        last_node ← n_near\n        last_node ← Grow RRT tree from last_node to some/all of intermediate q's\n        \n        if last node reaches the goal:\n            path ← backup the path recursively\n            return path\n        \n      return None","block_group":"c6c7c4f2662d49b29c78c166c6eec03f"},{"cellId":"a4db782a7547417995e2a6df4c3f056b","cell_type":"markdown","metadata":{"id":"lsRzky8W4nfb","cell_id":"a4db782a7547417995e2a6df4c3f056b","deepnote_cell_type":"markdown"},"source":"## Implement RRT\n\n**YOUR TASK:** Implement the RRT algorithm below. You may find it significantly easier to use the `RRT_tools`. \n**Note:** In your implementation, you should plan in configuration space. Your implementation will be graded on whether the last node of the path has reached the goal and the path is collision-free.","block_group":"a2ef863af283492c80646064282b5836"},{"cellId":"756e924176df4ff3b115d238cb255fb4","cell_type":"code","metadata":{"id":"YcvgX_B9w9RY","source_hash":"d778d80d","execution_start":1759200355073,"execution_millis":4,"execution_context_id":"9a288765-7619-4b0f-b9a7-5404c8ffeff1","cell_id":"756e924176df4ff3b115d238cb255fb4","deepnote_cell_type":"code"},"source":"def rrt_planning(\n    problem: IiwaProblem, max_iterations: int = 1000, prob_sample_q_goal: float = 0.05\n) -> tuple[list[tuple] | None, int]:\n    \"\"\"\n    Input:\n        problem (IiwaProblem): instance of a utility class\n        max_iterations: the maximum number of samples to be collected\n        prob_sample_q_goal: the probability of sampling q_goal\n\n    Output:\n    (path, iterations) (tuple):\n        path (list): [q_start, ..., q_goal]. Each element q is a configuration (not an RRT node).\n        iterations (int): The number of iterations executed to obtain the solution.\n                          If no solution is found, return (None, max_iterations).\n\n    \"\"\"\n    rrt_tools = RRT_tools(problem)\n    q_goal = problem.goal\n    q_start = problem.start\n\n    return None, max_iterations","block_group":"9821de0479174fe6a7cd63a2834cedb2","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"ce169f497f894bb8b9873631e4a43444","cell_type":"markdown","metadata":{"cell_id":"ce169f497f894bb8b9873631e4a43444","deepnote_cell_type":"markdown"},"source":"**Note:** You may need to run this a few times to find a valid path. Feel free to experiment with the numbers for`max_iterations` and `prob_sample_q_goal`. For `max_iterations = 1000`, it can take ~1 minute to run depending on your implementation.","block_group":"3dfa25f0f6d84638a3412b0a9ffc9c19"},{"cellId":"2ac76caf1f1645a786da5197118ab896","cell_type":"code","metadata":{"id":"I3ZOEcE9w9Rh","source_hash":"e5298523","execution_start":1759200361957,"execution_millis":5456,"execution_context_id":"9a288765-7619-4b0f-b9a7-5404c8ffeff1","cell_id":"2ac76caf1f1645a786da5197118ab896","deepnote_cell_type":"code"},"source":"path, num_iter = rrt_planning(\n    iiwa_problem, max_iterations=1000, prob_sample_q_goal=0.15\n)\nprint(f\"Number Iter: {num_iter}\")\nif path is not None:\n    print(\"Found a path!\")\nelse:\n    print(\"No path found\")","block_group":"09b1a164e7f549488695bfdfc5e0f0ff","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"2f87a1dc50c04e45896989638aa7e718","cell_type":"markdown","metadata":{"cell_id":"2f87a1dc50c04e45896989638aa7e718","deepnote_cell_type":"markdown"},"source":"## Check your Implementation\nRun the autograder below to check your implementation. It make take ~30 seconds to run.","block_group":"fc83bd3c354c4dfaa1c52ee07129c26f"},{"cellId":"6f472e65851d47168e788113609098a9","cell_type":"code","metadata":{"cell_id":"6f472e65851d47168e788113609098a9","deepnote_cell_type":"code"},"source":"from manipulation.exercises.grader import Grader\nfrom manipulation.exercises.trajectories.test_rrt_planning import TestRRT\n\nGrader.grade_output([TestRRT], [locals()], \"results.json\")\nGrader.print_test_results(\"results.json\")","block_group":"a5b11ab7d4844e31b64883296fad48b8","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"660d06d9d97c4289bb7e0baaec3579a8","cell_type":"markdown","metadata":{"id":"d852c3Oa5IVF","cell_id":"660d06d9d97c4289bb7e0baaec3579a8","deepnote_cell_type":"markdown"},"source":"## Simulate the Path!\nRun the code below to visualize the path on the robot arm. Do you notice the \"RRT Dance\"?\n\n**Note:** Because some trajectories move very close to objects, small execution errors can lead to slight collisions, visible as flashes of a contact force. This is okay. However, there should not be major collisions with very large forces present.","block_group":"e3a0225e8ff449d5844954ce8e4b080e"},{"cellId":"434da177297f44dd98e59b48656e06c1","cell_type":"code","metadata":{"source_hash":"242c06b1","execution_start":1759200376889,"execution_millis":25275,"execution_context_id":"9a288765-7619-4b0f-b9a7-5404c8ffeff1","cell_id":"434da177297f44dd98e59b48656e06c1","deepnote_cell_type":"code"},"source":"scenario = LoadScenario(filename=\"cupboard_scenario_mustard.yaml\")\nbuilder = DiagramBuilder()\nstation = MakeHardwareStation(scenario, meshcat=meshcat)\nbuilder.AddSystem(station)\nplant = station.GetSubsystemByName(\"plant\")\n\nif path is None:\n    path = [iiwa_problem.start, iiwa_problem.start]\n\ntimes = [0.05 * i for i in range(len(path))]\nQ = np.column_stack(path)\ntraj = PiecewisePolynomial.FirstOrderHold(times, Q)\n\niiwa_src = builder.AddSystem(TrajectorySource(traj))\nwsg_src = builder.AddSystem(ConstantVectorSource(np.array([0.1])))\n\nbuilder.Connect(iiwa_src.get_output_port(), station.GetInputPort(\"iiwa.position\"))\nbuilder.Connect(wsg_src.get_output_port(), station.GetInputPort(\"wsg.position\"))\n\ndiagram = builder.Build()\n\ndiagram_context = diagram.CreateDefaultContext()\nstation_context = diagram.GetSubsystemContext(station, diagram_context)\nstation.GetInputPort(\"wsg.position\").FixValue(station_context, [0.1])\n\nsimulation = Simulator(diagram)\n\nctx = simulation.get_mutable_context()\ndiagram.ForcedPublish(ctx)\n\nmeshcat.StartRecording()\n\nif running_as_notebook:\n    simulation.set_target_realtime_rate(1.0)\n\nsimulation.AdvanceTo(traj.end_time() if running_as_notebook else 0.1)\nmeshcat.StopRecording()\nmeshcat.PublishRecording()","block_group":"cb038cd280384718a73619716cb80429","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"61e8100981d94584a8d80a59c16a1941","cell_type":"markdown","metadata":{"id":"fMhnEoWWw9Rp","cell_id":"61e8100981d94584a8d80a59c16a1941","deepnote_cell_type":"markdown"},"source":"**Answer the following question regarding the properties of the RRT algorithm in Gradescope**\n\nConsider the case where we let our RRT algorithm run forever, i..e max_iterations is set to $\\infty$. If there is no path to the goal, will RRT warn you? If there is a path to the goal, will RRT eventually find that path? Explain your reasoning for both cases. \n","block_group":"41baf98bb34246248e8c5312f1204156"},{"cellId":"47d8f210e0ca44f7a888e9de70c6185f","cell_type":"markdown","metadata":{"cell_id":"47d8f210e0ca44f7a888e9de70c6185f","deepnote_cell_type":"markdown"},"source":"# RRT Connect Algorithm\n\nRRT-Connect builds on the basic RRT algorithm by growing two trees simultaneously: one rooted at the start and the other at the goal. At each iteration, one tree is expanded towards a random sample, and then the other tree attempts to connect directly to the newly added state. This alternating “extend and connect” strategy allows the two trees to rapidly explore the space from both directions, often meeting in the middle to form a complete path.\n\nLike RRT, the method retains the probabilistic bias towards unexplored regions, but it improves efficiency by aggressively trying to connect the trees whenever possible. In practice, this often yields faster convergence and shorter paths than a single-tree RRT.\n\nThe pseudocode of the RRT-Connect algorithm is shown below. For more details, see the [original paper](https://www.cs.cmu.edu/afs/cs/academic/class/15494-s12/readings/kuffner_icra2000.pdf).","block_group":"46fa74cc4cbb454684825610c03c35c0"},{"cellId":"87b3100a96a24769a38e3dc70acdb519","cell_type":"markdown","metadata":{"cell_id":"87b3100a96a24769a38e3dc70acdb519","deepnote_cell_type":"markdown"},"source":" **Algorithm RRT-Connect**\n\n    Input: q_start, q_goal, max_iterations, eps_connect\n    Output: path\n\n    // Initialize\n    TOOLS      ← RRT-CONNECT TOOLS\n    T_start    ← Make a tree at the starting configuration\n    T_goal     ← Make a tree at the goal configuration\n\n    //  Main loop\n    for it = 1 … MAX_ITERS:\n        q_rand  ← Sample Configuration\n\n        T_active, T_other  ← alternate which tree is active each iteration \n\n        status_a, node_a ← Attempt a single step extension of the active tree towards sample\n\n        if we are not trapped:\n            q_new ← the value of node_a // add the new node\n\n            status_b, node_b ← attempt a greedy connection between the other tree and q_new\n\n            if the trees connect:\n                // Backtrack partial paths from the connecting point to each root \n                path_a ← backtrack active tree from node_a\n                path_b ← backtrack other tree from node_b\n\n                If the active tree is the goal tree:\n                    swap(path_a, path_b)\n\n                PATH ← concatenate path_a with a reversed path_b\n                return (PATH, it)","block_group":"b6f394bd8d9b477986a6b394c3a1d64e"},{"cellId":"606aa2fac8f94a6389cd64928c3603a4","cell_type":"markdown","metadata":{"cell_id":"606aa2fac8f94a6389cd64928c3603a4","deepnote_cell_type":"markdown"},"source":"## RRT-Connect Utility Class\n\nBelow, we have provided you the important additional features you will need to implement the RRT-Connect algorithm. Note that `RRT_Connect_tools` is a subclass of `RRT_tools`. As a reminder, a robot configuration is referred to as $q$, whereas a node in the RRT tree is referred to as a node. One can access the configuration of a node by \n```\nq_sample = node.value\n```","block_group":"94d8e0963e73488288223e49f5c870ee"},{"cellId":"80d1676678854edc91e454427b6850cd","cell_type":"code","metadata":{"source_hash":"76950431","execution_start":1759200431015,"execution_millis":0,"execution_context_id":"9a288765-7619-4b0f-b9a7-5404c8ffeff1","cell_id":"80d1676678854edc91e454427b6850cd","deepnote_cell_type":"code"},"source":"class RRT_Connect_tools(RRT_tools):\n    def create_new_tree(self, q_root: tuple[float]) -> RRT:\n        return RRT(TreeNode(q_root), self.problem.cspace)\n\n    def extend_once(\n        self, tree: RRT, q_target: tuple[float], eps_connect: float = 1e-3\n    ) -> tuple[Literal[\"Trapped\", \"Reached\", \"Advanced\"], TreeNode]:\n        \"extends tree by one step towards q_target\"\n        q_near_node = tree.nearest(q_target)\n        edge = self.problem.safe_path(q_near_node.value, q_target)\n        if len(edge) <= 1:\n            return \"Trapped\", q_near_node\n\n        q_step = edge[1]\n        new_node = tree.add_configuration(q_near_node, q_step)\n\n        reached = q_step == q_target\n        if not reached:\n            if self.problem.cspace.distance(q_step, q_target) <= eps_connect:\n                tail_edge = self.problem.safe_path(q_step, q_target)\n                if len(tail_edge) > 1 and tail_edge[-1] == q_target:\n                    new_node = tree.add_configuration(new_node, q_target)\n                    reached = True\n\n        return (\"Reached\" if reached else \"Advanced\"), new_node\n\n    def connect_greedy(\n        self, tree: RRT, q_target: tuple[float], eps_connect: float = 1e-3\n    ) -> tuple[Literal[\"Trapped\", \"Reached\", \"Advanced\"], TreeNode | None]:\n        status, last = \"Advanced\", None\n        while status == \"Advanced\":\n            status, last = self.extend_once(tree, q_target, eps_connect)\n            if status == \"Trapped\":\n                return \"Trapped\", last\n        return \"Reached\", last\n\n    @staticmethod\n    def concat_paths(path_a: list[tuple], path_b: list[tuple]) -> list[tuple]:\n        if path_a and path_b and path_a[-1] == path_b[0]:\n            return path_a + path_b[1:]\n        return path_a + path_b","block_group":"4996e205277845a1a05ac69b2f6e326c","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"ca61ad411b664edeb57c8c9add60301b","cell_type":"markdown","metadata":{"cell_id":"ca61ad411b664edeb57c8c9add60301b","deepnote_cell_type":"markdown"},"source":"## Implement RRT-Connect\n\n**YOUR TASK:** Implement the RRT-Connect algorithm below. You may find it significantly easier to use the `RRT_Connect_tools`.\n\n**Note:** In your implementation, you should plan in configuration space. Your implementation will be graded on whether the last node of the path has reached the goal and the path is collision-free.","block_group":"f1fe32f64a7a44d19268a91a4b34f091"},{"cellId":"2ad70570c47e4b70a681811bd856110f","cell_type":"code","metadata":{"source_hash":"4f800ae4","execution_start":1759200435569,"execution_millis":2,"execution_context_id":"9a288765-7619-4b0f-b9a7-5404c8ffeff1","cell_id":"2ad70570c47e4b70a681811bd856110f","deepnote_cell_type":"code"},"source":"def rrt_connect_planning(\n    problem: IiwaProblem, max_iterations: int = 1000, eps_connect: float = 1e-2\n) -> tuple[list[tuple] | None, int]:\n    \"\"\"\n    Input:\n        problem (IiwaProblem): instance of a utility class\n        max_iterations: the maximum number of samples to be collected\n        eps_connect: how close the trees need to be within to connect\n\n    Output:\n    (path, iterations) (tuple):\n        path (list): [q_start, ..., q_goal]. Each element q is a configuration (not an RRT node).\n        iterations (int): The number of iterations executed to obtain the solution.\n                          If no solution is found, return (None, max_iterations).\n\n    \"\"\"\n\n    tools = RRT_Connect_tools(problem)\n    T_start = tools.rrt_tree\n    T_goal = tools.create_new_tree(problem.goal)\n\n    # TODO: Insert your code\n\n    return None, max_iterations","block_group":"9d64ff3506464dc3b24d21713a6439b1","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"3870741851374cdd9753b9d905679394","cell_type":"markdown","metadata":{"cell_id":"3870741851374cdd9753b9d905679394","deepnote_cell_type":"markdown"},"source":"**Note:** You may need to run this a few times to find a valid path. Feel free to experiment with the numbers for`max_iterations`. For `max_iterations = 1000`, it can take ~1 minute to run depending on your implementation.","block_group":"da321ad3cf2b41fe8876e8ed55b61a94"},{"cellId":"b5db266662de493a9eb0df2858358ad3","cell_type":"code","metadata":{"source_hash":"ca8187cb","execution_start":1759200441767,"execution_millis":2472,"execution_context_id":"9a288765-7619-4b0f-b9a7-5404c8ffeff1","cell_id":"b5db266662de493a9eb0df2858358ad3","deepnote_cell_type":"code"},"source":"path_connect, num_iter = rrt_connect_planning(iiwa_problem, 1000, 1e-2)\nprint(f\"Number Iter: {num_iter}\")\nif path is not None:\n    print(\"Found a path!\")\nelse:\n    print(\"No path found\")","block_group":"a46b5cdb53e9440f9c1a0e45ec19d5fd","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"c4371ee39dc145c498d249bc4b9f61c2","cell_type":"markdown","metadata":{"cell_id":"c4371ee39dc145c498d249bc4b9f61c2","deepnote_cell_type":"markdown"},"source":"## Check your Implementation\nRun the autograder below to check your implementation","block_group":"a1bb5a66f74b4364a2e638e11e0343d6"},{"cellId":"b0ce3024306045c18cb28a6352fa3ee1","cell_type":"code","metadata":{"cell_id":"b0ce3024306045c18cb28a6352fa3ee1","deepnote_cell_type":"code"},"source":"from manipulation.exercises.grader import Grader\nfrom manipulation.exercises.trajectories.test_rrt_planning import TestRRT_Connect\n\nGrader.grade_output([TestRRT_Connect], [locals()], \"results.json\")\nGrader.print_test_results(\"results.json\")","block_group":"74f7a35e5eaa49d9989a1eba712dd723","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"c8e9a69dc29b4beba5f6c2880e1afa19","cell_type":"markdown","metadata":{"cell_id":"c8e9a69dc29b4beba5f6c2880e1afa19","deepnote_cell_type":"markdown"},"source":"## Simulate the Path!\nRun the code below to visualize the path on the robot arm.","block_group":"de14a84b149f47bc9108e7c57e1f2ef5"},{"cellId":"2cfb70bdb5f140459bfe0efc8380d193","cell_type":"code","metadata":{"source_hash":"fe593de4","execution_start":1759200453111,"execution_millis":18075,"execution_context_id":"9a288765-7619-4b0f-b9a7-5404c8ffeff1","cell_id":"2cfb70bdb5f140459bfe0efc8380d193","deepnote_cell_type":"code"},"source":"scenario = LoadScenario(filename=\"cupboard_scenario_mustard.yaml\")\nbuilder = DiagramBuilder()\nstation = MakeHardwareStation(scenario, meshcat=meshcat)\nbuilder.AddSystem(station)\nplant = station.GetSubsystemByName(\"plant\")\n\nif path_connect is None:\n    path_connect = [iiwa_problem.start, iiwa_problem.start]\n\ntimes = [0.05 * i for i in range(len(path_connect))]\nQ = np.column_stack(path_connect)\ntraj = PiecewisePolynomial.FirstOrderHold(times, Q)\n\niiwa_src = builder.AddSystem(TrajectorySource(traj))\nwsg_src = builder.AddSystem(ConstantVectorSource(np.array([0.1])))\n\nbuilder.Connect(iiwa_src.get_output_port(), station.GetInputPort(\"iiwa.position\"))\nbuilder.Connect(wsg_src.get_output_port(), station.GetInputPort(\"wsg.position\"))\n\ndiagram = builder.Build()\n\ndiagram_context = diagram.CreateDefaultContext()\nstation_context = diagram.GetSubsystemContext(station, diagram_context)\nstation.GetInputPort(\"wsg.position\").FixValue(station_context, [0.1])\n\nsimulation = Simulator(diagram)\n\nctx = simulation.get_mutable_context()\ndiagram.ForcedPublish(ctx)\n\nmeshcat.StartRecording()\n\nif running_as_notebook:\n    simulation.set_target_realtime_rate(1.0)\n\nsimulation.AdvanceTo(traj.end_time() if running_as_notebook else 0.1)\nmeshcat.StopRecording()\nmeshcat.PublishRecording()","block_group":"6f35f62500fd4626a9866234876f8619","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"9db14a8c54394a0580f2b57714b49000","cell_type":"markdown","metadata":{"cell_id":"9db14a8c54394a0580f2b57714b49000","deepnote_cell_type":"markdown"},"source":"# Gradescope Verification\nTake a screen recording of the robot following your RRT-Connect trajectory and upload it to gradescope **as an mp4**. The file should be (much) smaller than 500MB. The robot should follow the path from $q_{start}$ to $q_{goal}$ planned by RRT-Connect while avoiding collisions with any obstacles in the environment.\n**Note:** Because some trajectories move very close to objects, small execution errors can lead to slight collisions, visible as flashes of a contact force. This is okay. However, there should not be major collisions with very large forces present.","block_group":"6380f37387754947a6b59316d0576804"}],
        "metadata": {"deepnote_notebook_id":"292446b59f244d599dcfa1a2af6fd9f8"},
        "nbformat": "4",
        "nbformat_minor": "0",
        "version": "0"
      }