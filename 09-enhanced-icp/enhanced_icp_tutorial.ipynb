{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced ICP: Soft Correspondences with Generalized-ICP\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In the previous pose estimation exercise, we used the Iterative Closest Point (ICP) algorithm to estimate object poses from point cloud data. While ICP works well in many scenarios, it has some limitations:\n",
    "\n",
    "1. **Hard correspondences**: Standard ICP assumes each point in one scan corresponds exactly to its nearest neighbor in the other scan\n",
    "2. **Sensitivity to incorrect matches**: Wrong correspondences can pull the alignment away from the correct solution\n",
    "3. **Discretization issues**: Different sampling of the same surface makes exact point overlap impossible\n",
    "\n",
    "In this tutorial, we'll explore **Generalized-ICP (GICP)**, a probabilistic extension that addresses these issues through *soft correspondences*. Instead of treating each match as a hard constraint, GICP models uncertainty in point positions and uses local surface structure from *both* scans.\n",
    "\n",
    "**What you'll learn:**\n",
    "- How point-to-plane ICP improves on standard ICP\n",
    "- The probabilistic framework behind Generalized-ICP\n",
    "- How to implement \"plane-to-plane\" matching with covariance matrices\n",
    "- Why GICP is more robust to incorrect correspondences\n",
    "\n",
    "**Source**: This tutorial is based on the paper \"Generalized-ICP\" by Segal, Haehnel, and Thrun (RSS 2009)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "from scipy.spatial import KDTree\n",
    "from pydrake.all import (\n",
    "    AddMultibodyPlantSceneGraph,\n",
    "    BaseField,\n",
    "    DiagramBuilder,\n",
    "    Fields,\n",
    "    MeshcatVisualizer,\n",
    "    Parser,\n",
    "    PointCloud,\n",
    "    Rgba,\n",
    "    RigidTransform,\n",
    "    RollPitchYaw,\n",
    "    RotationMatrix,\n",
    "    StartMeshcat,\n",
    ")\n",
    "\n",
    "from manipulation import running_as_notebook\n",
    "from manipulation.scenarios import AddMultibodyTriad\n",
    "from manipulation.station import AddPointClouds, LoadScenario, MakeHardwareStation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the visualizer\n",
    "meshcat = StartMeshcat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Model and Scene Point Clouds\n",
    "\n",
    "We'll use the same red foam brick example from the pose estimation exercise. This gives us a familiar setting to compare different ICP variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ToPointCloud(xyzs, rgbs=None):\n",
    "    \"\"\"Convert numpy arrays to Drake PointCloud object.\"\"\"\n",
    "    if rgbs is not None:\n",
    "        cloud = PointCloud(xyzs.shape[1], Fields(BaseField.kXYZs | BaseField.kRGBs))\n",
    "        cloud.mutable_rgbs()[:] = rgbs\n",
    "    else:\n",
    "        cloud = PointCloud(xyzs.shape[1])\n",
    "    cloud.mutable_xyzs()[:] = xyzs\n",
    "    return cloud\n",
    "\n",
    "\n",
    "def generate_model_pointcloud(xrange, yrange, zrange, res):\n",
    "    \"\"\"Generate a point cloud of a rectangular brick.\"\"\"\n",
    "    x_lst = np.linspace(xrange[0], xrange[1], int((xrange[1] - xrange[0]) / res))\n",
    "    y_lst = np.linspace(yrange[0], yrange[1], int((yrange[1] - yrange[0]) / res))\n",
    "    z_lst = np.linspace(zrange[0], zrange[1], int((zrange[1] - zrange[0]) / res))\n",
    "\n",
    "    pcl_lst = []\n",
    "    # XY Plane (top and bottom)\n",
    "    for x in x_lst:\n",
    "        for y in y_lst:\n",
    "            pcl_lst.append([x, y, zrange[0]])\n",
    "            pcl_lst.append([x, y, zrange[1]])\n",
    "\n",
    "    # YZ Plane (left and right)\n",
    "    for y in y_lst:\n",
    "        for z in z_lst:\n",
    "            pcl_lst.append([xrange[0], y, z])\n",
    "            pcl_lst.append([xrange[1], y, z])\n",
    "\n",
    "    # XZ Plane (front and back)\n",
    "    for x in x_lst:\n",
    "        for z in z_lst:\n",
    "            pcl_lst.append([x, yrange[0], z])\n",
    "            pcl_lst.append([x, yrange[1], z])\n",
    "\n",
    "    return np.array(pcl_lst).T\n",
    "\n",
    "\n",
    "def setup_clutter_station():\n",
    "    \"\"\"Set up the clutter station with camera and brick.\"\"\"\n",
    "    builder = DiagramBuilder()\n",
    "\n",
    "    scenario_data = \"\"\"\n",
    "directives:\n",
    "- add_model:\n",
    "    name: bin0\n",
    "    file: package://manipulation/hydro/bin.sdf\n",
    "\n",
    "- add_weld:\n",
    "    parent: world\n",
    "    child: bin0::bin_base\n",
    "    X_PC:\n",
    "      rotation: !Rpy { deg: [0.0, 0.0, 90.0 ]}\n",
    "      translation: [-0.145, -0.63, 0.075]\n",
    "\n",
    "- add_model:\n",
    "    name: brick\n",
    "    file: package://manipulation/hydro/061_foam_brick.sdf\n",
    "    default_free_body_pose:\n",
    "        base_link:\n",
    "            translation: [-0.1, -0.6, 0.09]\n",
    "            rotation: !Rpy { deg: [0, 0, 18] }\n",
    "\n",
    "- add_model:\n",
    "    name: camera\n",
    "    file: package://manipulation/camera_box.sdf\n",
    "- add_weld:\n",
    "    parent: world\n",
    "    child: camera::base\n",
    "    X_PC:\n",
    "        translation: [-0.1, -0.8, 0.5]\n",
    "        rotation: !Rpy { deg: [-150, 0, 0] }\n",
    "cameras:\n",
    "    main_camera:\n",
    "        name: camera0\n",
    "        depth: True\n",
    "        X_PB:\n",
    "            base_frame: camera::base\n",
    "\"\"\"\n",
    "\n",
    "    scenario = LoadScenario(data=scenario_data)\n",
    "    station = builder.AddSystem(MakeHardwareStation(scenario, meshcat))\n",
    "    plant = station.GetSubsystemByName(\"plant\")\n",
    "\n",
    "    # Add point cloud output\n",
    "    to_point_cloud = AddPointClouds(\n",
    "        scenario=scenario, station=station, builder=builder, meshcat=meshcat\n",
    "    )\n",
    "    if isinstance(to_point_cloud, list):\n",
    "        builder.ExportOutput(to_point_cloud[0].get_output_port(), \"camera_point_cloud\")\n",
    "    else:\n",
    "        builder.ExportOutput(\n",
    "            to_point_cloud[\"camera0\"].get_output_port(), \"camera_point_cloud\"\n",
    "        )\n",
    "\n",
    "    diagram = builder.Build()\n",
    "    return diagram\n",
    "\n",
    "\n",
    "# Generate model point cloud\n",
    "model_pcl = generate_model_pointcloud(\n",
    "    [-0.0375, 0.0375], [-0.025, 0.025], [0.0, 0.05], 0.003\n",
    ")\n",
    "\n",
    "# Get scene point cloud\n",
    "diagram = setup_clutter_station()\n",
    "context = diagram.CreateDefaultContext()\n",
    "scene_pcl_drake = (\n",
    "    diagram.GetOutputPort(\"camera_point_cloud\")\n",
    "    .Eval(context)\n",
    "    .Crop(lower_xyz=[-5, -5, -5], upper_xyz=[5, 5, 5])\n",
    ")\n",
    "\n",
    "# Get ground truth pose\n",
    "plant = diagram.GetSubsystemByName(\"station\").GetSubsystemByName(\"plant\")\n",
    "plant_context = plant.GetMyContextFromRoot(context)\n",
    "X_WO_true = plant.EvalBodyPoseInWorld(plant_context, plant.GetBodyByName(\"base_link\"))\n",
    "\n",
    "print(f\"Model point cloud: {model_pcl.shape[1]} points\")\n",
    "print(f\"Scene point cloud: {scene_pcl_drake.size()} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation: Extracting the Brick\n",
    "\n",
    "Before running ICP, we need to segment the brick from the background. We'll use a simple color-based segmentation since the brick is distinctly red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_brick(scene_pcl_drake):\n",
    "    \"\"\"Segment the red brick from the scene using color.\"\"\"\n",
    "    xyzs = scene_pcl_drake.xyzs()\n",
    "    rgbs = scene_pcl_drake.rgbs()\n",
    "    \n",
    "    # Filter for red color (R > 100, G < 80, B < 80)\n",
    "    red_mask = (rgbs[0, :] > 100) & (rgbs[1, :] < 80) & (rgbs[2, :] < 80)\n",
    "    \n",
    "    # Also filter by approximate position (z > 0.05 to avoid floor)\n",
    "    height_mask = xyzs[2, :] > 0.07\n",
    "    \n",
    "    combined_mask = red_mask & height_mask\n",
    "    \n",
    "    return xyzs[:, combined_mask]\n",
    "\n",
    "\n",
    "scene_pcl = segment_brick(scene_pcl_drake)\n",
    "print(f\"Segmented scene point cloud: {scene_pcl.shape[1]} points\")\n",
    "\n",
    "# Visualize\n",
    "meshcat.Delete()\n",
    "meshcat.SetObject(\"model\", ToPointCloud(model_pcl), rgba=Rgba(0, 0, 1, 1))\n",
    "meshcat.SetObject(\"scene\", ToPointCloud(scene_pcl), rgba=Rgba(1, 0, 0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review: Standard ICP\n",
    "\n",
    "Standard ICP minimizes the point-to-point distance between corresponding points:\n",
    "\n",
    "$$T^* = \\arg\\min_T \\sum_i \\|T \\cdot b_i - m_i\\|^2$$\n",
    "\n",
    "where $b_i$ are scene points, $m_i$ are their nearest neighbors in the model, and $T$ is the transformation.\n",
    "\n",
    "**Limitations**:\n",
    "- Assumes exact correspondence (both scans sample the exact same points)\n",
    "- Sensitive to incorrect matches\n",
    "- Penalizes sliding along surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_icp(model_pts, scene_pts, initial_transform, max_iterations=30, tolerance=1e-6):\n",
    "    \"\"\"\n",
    "    Standard point-to-point ICP.\n",
    "    \n",
    "    Args:\n",
    "        model_pts: 3xN array of model points\n",
    "        scene_pts: 3xM array of scene points\n",
    "        initial_transform: Initial RigidTransform guess\n",
    "        max_iterations: Maximum number of iterations\n",
    "        tolerance: Convergence threshold\n",
    "    \n",
    "    Returns:\n",
    "        Final RigidTransform and list of errors per iteration\n",
    "    \"\"\"\n",
    "    T = initial_transform\n",
    "    kdtree = KDTree(model_pts.T)\n",
    "    errors = []\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        # Transform scene points\n",
    "        scene_transformed = T.multiply(scene_pts)\n",
    "        \n",
    "        # Find correspondences\n",
    "        distances, indices = kdtree.query(scene_transformed.T)\n",
    "        correspondences = model_pts[:, indices]\n",
    "        \n",
    "        # Compute error\n",
    "        error = np.mean(distances)\n",
    "        errors.append(error)\n",
    "        \n",
    "        if iteration > 0 and abs(errors[-2] - errors[-1]) < tolerance:\n",
    "            break\n",
    "        \n",
    "        # Compute centroids\n",
    "        centroid_scene = np.mean(scene_transformed, axis=1)\n",
    "        centroid_model = np.mean(correspondences, axis=1)\n",
    "        \n",
    "        # Center the points\n",
    "        scene_centered = scene_transformed - centroid_scene.reshape(3, 1)\n",
    "        model_centered = correspondences - centroid_model.reshape(3, 1)\n",
    "        \n",
    "        # Compute optimal rotation using SVD\n",
    "        H = scene_centered @ model_centered.T\n",
    "        U, _, Vt = np.linalg.svd(H)\n",
    "        R = Vt.T @ U.T\n",
    "        \n",
    "        # Ensure proper rotation (det(R) = 1)\n",
    "        if np.linalg.det(R) < 0:\n",
    "            Vt[-1, :] *= -1\n",
    "            R = Vt.T @ U.T\n",
    "        \n",
    "        # Compute optimal translation\n",
    "        t = centroid_model - R @ centroid_scene\n",
    "        \n",
    "        # Update transform\n",
    "        T_update = RigidTransform(RotationMatrix(R), t)\n",
    "        T = T_update.multiply(T)\n",
    "    \n",
    "    return T, errors\n",
    "\n",
    "\n",
    "# Run standard ICP\n",
    "initial_guess = RigidTransform()\n",
    "initial_guess.set_translation([-0.145, -0.63, 0.09])\n",
    "initial_guess.set_rotation(RotationMatrix.MakeZRotation(np.pi / 2))\n",
    "\n",
    "T_standard, errors_standard = standard_icp(model_pcl, scene_pcl, initial_guess)\n",
    "\n",
    "# Compute error from ground truth\n",
    "X_error_standard = T_standard.inverse().multiply(X_WO_true)\n",
    "rpy_error_standard = RollPitchYaw(X_error_standard.rotation()).vector()\n",
    "xyz_error_standard = X_error_standard.translation()\n",
    "\n",
    "print(\"\\nStandard ICP Results:\")\n",
    "print(f\"Iterations: {len(errors_standard)}\")\n",
    "print(f\"Final error: {errors_standard[-1]:.6f}\")\n",
    "print(f\"RPY error (deg): [{rpy_error_standard[0]*180/np.pi:.2f}, {rpy_error_standard[1]*180/np.pi:.2f}, {rpy_error_standard[2]*180/np.pi:.2f}]\")\n",
    "print(f\"XYZ error (m): {xyz_error_standard}\")\n",
    "\n",
    "# Visualize\n",
    "meshcat.SetObject(\"icp_standard\", ToPointCloud(model_pcl), rgba=Rgba(0, 1, 0, 0.5))\n",
    "meshcat.SetTransform(\"icp_standard\", T_standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point-to-Plane ICP\n",
    "\n",
    "Point-to-plane ICP improves on standard ICP by using surface normal information. Instead of minimizing point-to-point distance, it minimizes the distance along the surface normal:\n",
    "\n",
    "$$T^* = \\arg\\min_T \\sum_i \\|\\mathbf{n}_i \\cdot (T \\cdot b_i - m_i)\\|^2$$\n",
    "\n",
    "where $\\mathbf{n}_i$ is the surface normal at point $m_i$.\n",
    "\n",
    "**Why is this better?**\n",
    "- Doesn't penalize sliding along the surface\n",
    "- Handles discretization better (different sampling doesn't matter as much)\n",
    "- Typically converges faster and more accurately\n",
    "\n",
    "**Key component**: Computing surface normals using local neighborhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_normals(points, k_neighbors=20):\n",
    "    \"\"\"\n",
    "    Compute surface normals using PCA on local neighborhoods.\n",
    "    \n",
    "    Args:\n",
    "        points: 3xN array of points\n",
    "        k_neighbors: Number of neighbors to use for PCA\n",
    "    \n",
    "    Returns:\n",
    "        3xN array of surface normals (unit vectors)\n",
    "    \"\"\"\n",
    "    kdtree = KDTree(points.T)\n",
    "    normals = np.zeros_like(points)\n",
    "    \n",
    "    for i in range(points.shape[1]):\n",
    "        # Find k nearest neighbors\n",
    "        _, indices = kdtree.query(points[:, i], k=k_neighbors)\n",
    "        neighbors = points[:, indices]\n",
    "        \n",
    "        # Compute covariance matrix\n",
    "        centroid = np.mean(neighbors, axis=1, keepdims=True)\n",
    "        centered = neighbors - centroid\n",
    "        cov = centered @ centered.T\n",
    "        \n",
    "        # Normal is eigenvector with smallest eigenvalue\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(cov)\n",
    "        normal = eigenvectors[:, 0]  # Smallest eigenvalue\n",
    "        \n",
    "        normals[:, i] = normal\n",
    "    \n",
    "    return normals\n",
    "\n",
    "\n",
    "def point_to_plane_icp(model_pts, scene_pts, initial_transform, max_iterations=30, tolerance=1e-6):\n",
    "    \"\"\"\n",
    "    Point-to-plane ICP using surface normals from the model.\n",
    "    \n",
    "    Uses linearization of the rotation for optimization.\n",
    "    \"\"\"\n",
    "    T = initial_transform\n",
    "    kdtree = KDTree(model_pts.T)\n",
    "    model_normals = compute_normals(model_pts)\n",
    "    errors = []\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        # Transform scene points\n",
    "        scene_transformed = T.multiply(scene_pts)\n",
    "        \n",
    "        # Find correspondences\n",
    "        distances, indices = kdtree.query(scene_transformed.T)\n",
    "        correspondences = model_pts[:, indices]\n",
    "        normals = model_normals[:, indices]\n",
    "        \n",
    "        # Compute point-to-plane error\n",
    "        diff = scene_transformed - correspondences\n",
    "        error = np.mean(np.abs(np.sum(diff * normals, axis=0)))\n",
    "        errors.append(error)\n",
    "        \n",
    "        if iteration > 0 and abs(errors[-2] - errors[-1]) < tolerance:\n",
    "            break\n",
    "        \n",
    "        # Build linear system A * x = b\n",
    "        # x = [alpha, beta, gamma, tx, ty, tz] (rotation angles and translation)\n",
    "        A = []\n",
    "        b = []\n",
    "        \n",
    "        for i in range(scene_transformed.shape[1]):\n",
    "            p = scene_transformed[:, i]\n",
    "            n = normals[:, i]\n",
    "            q = correspondences[:, i]\n",
    "            \n",
    "            # Linearized point-to-plane constraint\n",
    "            # n^T * ([p]_x * omega + t) = n^T * (q - p)\n",
    "            cross = np.array([\n",
    "                [0, -p[2], p[1]],\n",
    "                [p[2], 0, -p[0]],\n",
    "                [-p[1], p[0], 0]\n",
    "            ])\n",
    "            \n",
    "            row = np.concatenate([cross.T @ n, n])\n",
    "            A.append(row)\n",
    "            b.append(n.T @ (q - p))\n",
    "        \n",
    "        A = np.array(A)\n",
    "        b = np.array(b)\n",
    "        \n",
    "        # Solve least squares\n",
    "        x = np.linalg.lstsq(A, b, rcond=None)[0]\n",
    "        \n",
    "        # Extract rotation and translation\n",
    "        omega = x[:3]\n",
    "        t = x[3:]\n",
    "        \n",
    "        # Build incremental transform (small angle approximation)\n",
    "        angle = np.linalg.norm(omega)\n",
    "        if angle > 1e-10:\n",
    "            axis = omega / angle\n",
    "            R_update = RotationMatrix(np.cos(angle) * np.eye(3) + \n",
    "                                      (1 - np.cos(angle)) * np.outer(axis, axis) +\n",
    "                                      np.sin(angle) * np.array([\n",
    "                                          [0, -axis[2], axis[1]],\n",
    "                                          [axis[2], 0, -axis[0]],\n",
    "                                          [-axis[1], axis[0], 0]\n",
    "                                      ]))\n",
    "        else:\n",
    "            R_update = RotationMatrix(np.eye(3))\n",
    "        \n",
    "        T_update = RigidTransform(R_update, t)\n",
    "        T = T_update.multiply(T)\n",
    "    \n",
    "    return T, errors\n",
    "\n",
    "\n",
    "# Run point-to-plane ICP\n",
    "T_p2plane, errors_p2plane = point_to_plane_icp(model_pcl, scene_pcl, initial_guess)\n",
    "\n",
    "# Compute error from ground truth\n",
    "X_error_p2plane = T_p2plane.inverse().multiply(X_WO_true)\n",
    "rpy_error_p2plane = RollPitchYaw(X_error_p2plane.rotation()).vector()\n",
    "xyz_error_p2plane = X_error_p2plane.translation()\n",
    "\n",
    "print(\"\\nPoint-to-Plane ICP Results:\")\n",
    "print(f\"Iterations: {len(errors_p2plane)}\")\n",
    "print(f\"Final error: {errors_p2plane[-1]:.6f}\")\n",
    "print(f\"RPY error (deg): [{rpy_error_p2plane[0]*180/np.pi:.2f}, {rpy_error_p2plane[1]*180/np.pi:.2f}, {rpy_error_p2plane[2]*180/np.pi:.2f}]\")\n",
    "print(f\"XYZ error (m): {xyz_error_p2plane}\")\n",
    "\n",
    "# Visualize\n",
    "meshcat.SetObject(\"icp_p2plane\", ToPointCloud(model_pcl), rgba=Rgba(1, 1, 0, 0.5))\n",
    "meshcat.SetTransform(\"icp_p2plane\", T_p2plane)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized-ICP: The Probabilistic Framework\n",
    "\n",
    "### The Key Insight\n",
    "\n",
    "Standard ICP and point-to-plane ICP both have a key assumption: **one-way matching**. Point-to-plane only uses normals from the model scan, not the scene scan. But why should we privilege one scan over the other?\n",
    "\n",
    "**Generalized-ICP** models the problem probabilistically:\n",
    "\n",
    "1. Each measured point is drawn from a Gaussian distribution centered at the \"true\" point\n",
    "2. The covariance of this Gaussian reflects our uncertainty about the point's position\n",
    "3. We can model **local surface structure** with covariance matrices\n",
    "\n",
    "### Soft Correspondences\n",
    "\n",
    "Instead of treating each match as a hard constraint, GICP weights matches by their **geometric consistency**:\n",
    "\n",
    "- If two matched points have similar surface orientations → **strong constraint** (low covariance along both normals)\n",
    "- If two matched points have different orientations → **weak constraint** (high covariance, less influence)\n",
    "\n",
    "This naturally down-weights incorrect correspondences!\n",
    "\n",
    "### The Math (Simplified)\n",
    "\n",
    "We model each point with a covariance matrix that's:\n",
    "- **Small** along the surface normal (we know position along normal accurately)\n",
    "- **Large** along the surface plane (uncertain about exact position in plane)\n",
    "\n",
    "For a point with normal $\\mathbf{n}$, the covariance is:\n",
    "\n",
    "$$C = R \\begin{bmatrix} \\epsilon & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} R^T$$\n",
    "\n",
    "where $R$ rotates so that $\\epsilon$ aligns with $\\mathbf{n}$, and $\\epsilon \\ll 1$ (typically $\\epsilon \\approx 0.001$).\n",
    "\n",
    "The optimization then minimizes:\n",
    "\n",
    "$$T^* = \\arg\\min_T \\sum_i d_i^T (C_i^A + T C_i^B T^T)^{-1} d_i$$\n",
    "\n",
    "where $d_i = T \\cdot b_i - a_i$ is the point difference, and $C_i^A, C_i^B$ are the covariance matrices for both matched points.\n",
    "\n",
    "**This is \"plane-to-plane\" matching!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation: Computing Covariance Matrices\n",
    "\n",
    "The key new component in GICP is computing covariance matrices for each point based on local surface structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_covariances(points, normals, epsilon=0.001):\n",
    "    \"\"\"\n",
    "    Compute covariance matrices for each point based on local surface.\n",
    "    \n",
    "    Args:\n",
    "        points: 3xN array of points\n",
    "        normals: 3xN array of surface normals\n",
    "        epsilon: Small value for covariance along normal direction\n",
    "    \n",
    "    Returns:\n",
    "        List of N 3x3 covariance matrices\n",
    "    \"\"\"\n",
    "    covariances = []\n",
    "    \n",
    "    for i in range(points.shape[1]):\n",
    "        n = normals[:, i]\n",
    "        n = n / np.linalg.norm(n)  # Ensure unit normal\n",
    "        \n",
    "        # Find rotation that aligns e1 = [1,0,0] with normal\n",
    "        # We'll use the normal and two orthogonal tangent vectors\n",
    "        \n",
    "        # Find an arbitrary vector not parallel to n\n",
    "        if abs(n[0]) < 0.9:\n",
    "            v = np.array([1, 0, 0])\n",
    "        else:\n",
    "            v = np.array([0, 1, 0])\n",
    "        \n",
    "        # Gram-Schmidt to get orthonormal basis\n",
    "        t1 = v - (v @ n) * n\n",
    "        t1 = t1 / np.linalg.norm(t1)\n",
    "        t2 = np.cross(n, t1)\n",
    "        \n",
    "        # Build rotation matrix [n, t1, t2]\n",
    "        R = np.column_stack([n, t1, t2])\n",
    "        \n",
    "        # Covariance in local frame: small along normal, large along tangents\n",
    "        C_local = np.diag([epsilon, 1.0, 1.0])\n",
    "        \n",
    "        # Transform to world frame\n",
    "        C = R @ C_local @ R.T\n",
    "        \n",
    "        covariances.append(C)\n",
    "    \n",
    "    return covariances\n",
    "\n",
    "\n",
    "# Compute covariances for both model and scene\n",
    "model_normals = compute_normals(model_pcl)\n",
    "scene_normals = compute_normals(scene_pcl)\n",
    "\n",
    "model_covariances = compute_covariances(model_pcl, model_normals)\n",
    "scene_covariances = compute_covariances(scene_pcl, scene_normals)\n",
    "\n",
    "print(f\"Computed {len(model_covariances)} model covariances\")\n",
    "print(f\"Computed {len(scene_covariances)} scene covariances\")\n",
    "print(f\"\\nExample covariance matrix:\")\n",
    "print(model_covariances[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Covariance Matrices\n",
    "\n",
    "Let's visualize what these covariance matrices look like. They should be \"pancake-shaped\" - thin along the normal, wide along the surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_covariance_ellipsoid(meshcat, name, point, covariance, scale=3.0, rgba=Rgba(1, 0, 1, 0.3)):\n",
    "    \"\"\"\n",
    "    Visualize a covariance matrix as an ellipsoid in meshcat.\n",
    "    \n",
    "    The ellipsoid axes are given by the eigenvectors, scaled by sqrt(eigenvalues).\n",
    "    \"\"\"\n",
    "    # Eigen decomposition\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(covariance)\n",
    "    \n",
    "    # Build transform: rotation from eigenvectors, translation from point\n",
    "    R = RotationMatrix(eigenvectors)\n",
    "    t = point\n",
    "    X = RigidTransform(R, t)\n",
    "    \n",
    "    # Scale by sqrt of eigenvalues\n",
    "    scales = np.sqrt(eigenvalues) * scale\n",
    "    \n",
    "    from pydrake.geometry import Sphere\n",
    "    sphere = Sphere(1.0)\n",
    "    meshcat.SetObject(name, sphere, rgba)\n",
    "    \n",
    "    # Apply transform with non-uniform scaling\n",
    "    # Note: meshcat doesn't support non-uniform scaling directly,\n",
    "    # so we'll just show the direction with small spheres\n",
    "    meshcat.SetTransform(name, X)\n",
    "\n",
    "\n",
    "# Visualize a few covariance ellipsoids\n",
    "num_to_show = 5\n",
    "indices = np.linspace(0, model_pcl.shape[1]-1, num_to_show, dtype=int)\n",
    "\n",
    "for idx, i in enumerate(indices):\n",
    "    point = model_pcl[:, i]\n",
    "    normal = model_normals[:, i]\n",
    "    cov = model_covariances[i]\n",
    "    \n",
    "    # Show normal as an arrow\n",
    "    from pydrake.geometry import Cylinder\n",
    "    arrow = Cylinder(0.001, 0.02)\n",
    "    meshcat.SetObject(f\"normal_{idx}\", arrow, Rgba(0, 1, 0, 1))\n",
    "    \n",
    "    # Orient arrow along normal\n",
    "    # Default cylinder is along z-axis\n",
    "    z_axis = np.array([0, 0, 1])\n",
    "    if np.linalg.norm(normal - z_axis) > 1e-6:\n",
    "        axis = np.cross(z_axis, normal)\n",
    "        axis = axis / np.linalg.norm(axis)\n",
    "        angle = np.arccos(np.dot(z_axis, normal))\n",
    "        R = RotationMatrix(np.cos(angle/2) * np.eye(3) + \n",
    "                          np.sin(angle/2) * np.array([\n",
    "                              [0, -axis[2], axis[1]],\n",
    "                              [axis[2], 0, -axis[0]],\n",
    "                              [-axis[1], axis[0], 0]\n",
    "                          ]))\n",
    "    else:\n",
    "        R = RotationMatrix.Identity()\n",
    "    \n",
    "    X_arrow = RigidTransform(R, point + normal * 0.01)\n",
    "    meshcat.SetTransform(f\"normal_{idx}\", X_arrow)\n",
    "\n",
    "print(\"Visualized covariance ellipsoids and normals (green arrows)\")\n",
    "print(\"The covariances are 'pancake-shaped': thin along the normal, wide along the surface.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Generalized-ICP\n",
    "\n",
    "Now we can implement the full GICP algorithm using our covariance matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalized_icp(model_pts, scene_pts, model_cov, scene_cov, \n",
    "                   initial_transform, max_iterations=30, tolerance=1e-6):\n",
    "    \"\"\"\n",
    "    Generalized-ICP with plane-to-plane matching.\n",
    "    \n",
    "    Args:\n",
    "        model_pts: 3xN array of model points\n",
    "        scene_pts: 3xM array of scene points\n",
    "        model_cov: List of N 3x3 covariance matrices for model\n",
    "        scene_cov: List of M 3x3 covariance matrices for scene\n",
    "        initial_transform: Initial RigidTransform guess\n",
    "        max_iterations: Maximum number of iterations\n",
    "        tolerance: Convergence threshold\n",
    "    \n",
    "    Returns:\n",
    "        Final RigidTransform and list of errors per iteration\n",
    "    \"\"\"\n",
    "    T = initial_transform\n",
    "    kdtree = KDTree(model_pts.T)\n",
    "    errors = []\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        # Transform scene points\n",
    "        R_mat = T.rotation().matrix()\n",
    "        t_vec = T.translation()\n",
    "        scene_transformed = R_mat @ scene_pts + t_vec.reshape(3, 1)\n",
    "        \n",
    "        # Find correspondences\n",
    "        distances, indices = kdtree.query(scene_transformed.T)\n",
    "        correspondences = model_pts[:, indices]\n",
    "        \n",
    "        # Build linear system for incremental update\n",
    "        A = []\n",
    "        b_vec = []\n",
    "        total_error = 0\n",
    "        \n",
    "        for i in range(scene_transformed.shape[1]):\n",
    "            p_scene = scene_transformed[:, i]\n",
    "            p_model = correspondences[:, i]\n",
    "            \n",
    "            # Get covariance matrices\n",
    "            C_scene = scene_cov[i]\n",
    "            C_model = model_cov[indices[i]]\n",
    "            \n",
    "            # Transform scene covariance to world frame\n",
    "            C_scene_world = R_mat @ C_scene @ R_mat.T\n",
    "            \n",
    "            # Combined covariance\n",
    "            C_combined = C_model + C_scene_world\n",
    "            \n",
    "            # Regularize to avoid singularity\n",
    "            C_combined += np.eye(3) * 1e-6\n",
    "            \n",
    "            # Inverse covariance (precision matrix)\n",
    "            C_inv = np.linalg.inv(C_combined)\n",
    "            \n",
    "            # Point difference\n",
    "            d = p_scene - p_model\n",
    "            \n",
    "            # Error (Mahalanobis distance)\n",
    "            total_error += d.T @ C_inv @ d\n",
    "            \n",
    "            # Build linear constraint\n",
    "            # Linearize: d ≈ [p]_x * omega + t + d_0\n",
    "            # where omega is rotation increment, t is translation increment\n",
    "            \n",
    "            cross = np.array([\n",
    "                [0, -p_scene[2], p_scene[1]],\n",
    "                [p_scene[2], 0, -p_scene[0]],\n",
    "                [-p_scene[1], p_scene[0], 0]\n",
    "            ])\n",
    "            \n",
    "            # Jacobian: [dp/domega, dp/dt] = [[p]_x, I]\n",
    "            J = np.hstack([cross, np.eye(3)])\n",
    "            \n",
    "            # Weighted constraint: J^T * C_inv * J * x = -J^T * C_inv * d\n",
    "            A.append(J.T @ C_inv @ J)\n",
    "            b_vec.append(-J.T @ C_inv @ d)\n",
    "        \n",
    "        # Accumulate and solve\n",
    "        A_total = np.sum(A, axis=0)\n",
    "        b_total = np.sum(b_vec, axis=0)\n",
    "        \n",
    "        # Solve for incremental update\n",
    "        x = np.linalg.solve(A_total, b_total)\n",
    "        \n",
    "        omega = x[:3]\n",
    "        t_update = x[3:]\n",
    "        \n",
    "        # Build incremental transform\n",
    "        angle = np.linalg.norm(omega)\n",
    "        if angle > 1e-10:\n",
    "            axis = omega / angle\n",
    "            # Rodrigues' formula\n",
    "            K = np.array([\n",
    "                [0, -axis[2], axis[1]],\n",
    "                [axis[2], 0, -axis[0]],\n",
    "                [-axis[1], axis[0], 0]\n",
    "            ])\n",
    "            R_update_mat = np.eye(3) + np.sin(angle) * K + (1 - np.cos(angle)) * (K @ K)\n",
    "            R_update = RotationMatrix(R_update_mat)\n",
    "        else:\n",
    "            R_update = RotationMatrix.Identity()\n",
    "        \n",
    "        T_update = RigidTransform(R_update, t_update)\n",
    "        T = T_update.multiply(T)\n",
    "        \n",
    "        # Record error\n",
    "        avg_error = total_error / scene_transformed.shape[1]\n",
    "        errors.append(avg_error)\n",
    "        \n",
    "        # Check convergence\n",
    "        if iteration > 0 and abs(errors[-2] - errors[-1]) < tolerance:\n",
    "            break\n",
    "    \n",
    "    return T, errors\n",
    "\n",
    "\n",
    "# Run Generalized-ICP\n",
    "T_gicp, errors_gicp = generalized_icp(\n",
    "    model_pcl, scene_pcl, \n",
    "    model_covariances, scene_covariances,\n",
    "    initial_guess\n",
    ")\n",
    "\n",
    "# Compute error from ground truth\n",
    "X_error_gicp = T_gicp.inverse().multiply(X_WO_true)\n",
    "rpy_error_gicp = RollPitchYaw(X_error_gicp.rotation()).vector()\n",
    "xyz_error_gicp = X_error_gicp.translation()\n",
    "\n",
    "print(\"\\nGeneralized-ICP Results:\")\n",
    "print(f\"Iterations: {len(errors_gicp)}\")\n",
    "print(f\"Final error: {errors_gicp[-1]:.6f}\")\n",
    "print(f\"RPY error (deg): [{rpy_error_gicp[0]*180/np.pi:.2f}, {rpy_error_gicp[1]*180/np.pi:.2f}, {rpy_error_gicp[2]*180/np.pi:.2f}]\")\n",
    "print(f\"XYZ error (m): {xyz_error_gicp}\")\n",
    "\n",
    "# Visualize\n",
    "meshcat.SetObject(\"icp_gicp\", ToPointCloud(model_pcl), rgba=Rgba(1, 0, 1, 0.5))\n",
    "meshcat.SetTransform(\"icp_gicp\", T_gicp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: All Three Methods\n",
    "\n",
    "Let's compare the convergence and accuracy of all three ICP variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot convergence curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(errors_standard, 'b-', label='Standard ICP', linewidth=2)\n",
    "plt.plot(errors_p2plane, 'g-', label='Point-to-Plane ICP', linewidth=2)\n",
    "plt.plot(errors_gicp, 'r-', label='Generalized-ICP', linewidth=2)\n",
    "plt.xlabel('Iteration', fontsize=12)\n",
    "plt.ylabel('Error', fontsize=12)\n",
    "plt.title('Convergence Comparison', fontsize=14)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Method':<25} {'Iterations':<15} {'Final Error':<15} {'Pose Error (m)'}\")\n",
    "print(\"-\"*80)\n",
    "print(f\"{'Standard ICP':<25} {len(errors_standard):<15} {errors_standard[-1]:<15.6f} {np.linalg.norm(xyz_error_standard):.6f}\")\n",
    "print(f\"{'Point-to-Plane ICP':<25} {len(errors_p2plane):<15} {errors_p2plane[-1]:<15.6f} {np.linalg.norm(xyz_error_p2plane):.6f}\")\n",
    "print(f\"{'Generalized-ICP':<25} {len(errors_gicp):<15} {errors_gicp[-1]:<15.6f} {np.linalg.norm(xyz_error_gicp):.6f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nKey Observations:\")\n",
    "print(\"1. Point-to-Plane typically converges faster than Standard ICP\")\n",
    "print(\"2. Generalized-ICP often achieves similar or better accuracy\")\n",
    "print(\"3. GICP's main advantage is robustness (demonstrated in next section)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Robustness: Handling Incorrect Correspondences\n",
    "\n",
    "The key advantage of GICP is its robustness to incorrect correspondences. Let's test this by:\n",
    "1. Adding noise to the initial guess\n",
    "2. Testing with partial overlap (occlusions)\n",
    "3. Varying the maximum correspondence distance threshold\n",
    "\n",
    "### Test 1: Noisy Initial Guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_noise(translation_noise=0.05, rotation_noise=0.3):\n",
    "    \"\"\"\n",
    "    Test all three ICP methods with added noise to the initial guess.\n",
    "    \"\"\"\n",
    "    # Add noise to initial guess\n",
    "    noisy_guess = RigidTransform(initial_guess)\n",
    "    t = initial_guess.translation() + np.random.randn(3) * translation_noise\n",
    "    rpy = RollPitchYaw(initial_guess.rotation()).vector() + np.random.randn(3) * rotation_noise\n",
    "    noisy_guess.set_translation(t)\n",
    "    noisy_guess.set_rotation(RollPitchYaw(rpy).ToRotationMatrix())\n",
    "    \n",
    "    print(f\"\\nTesting with noise: ±{translation_noise}m translation, ±{rotation_noise}rad rotation\")\n",
    "    \n",
    "    # Run all methods\n",
    "    try:\n",
    "        T_std, err_std = standard_icp(model_pcl, scene_pcl, noisy_guess, max_iterations=30)\n",
    "        error_std = np.linalg.norm(T_std.inverse().multiply(X_WO_true).translation())\n",
    "        print(f\"Standard ICP:      Converged in {len(err_std)} iterations, error = {error_std:.6f}m\")\n",
    "    except:\n",
    "        print(f\"Standard ICP:      Failed to converge\")\n",
    "        error_std = np.inf\n",
    "    \n",
    "    try:\n",
    "        T_p2p, err_p2p = point_to_plane_icp(model_pcl, scene_pcl, noisy_guess, max_iterations=30)\n",
    "        error_p2p = np.linalg.norm(T_p2p.inverse().multiply(X_WO_true).translation())\n",
    "        print(f\"Point-to-Plane:    Converged in {len(err_p2p)} iterations, error = {error_p2p:.6f}m\")\n",
    "    except:\n",
    "        print(f\"Point-to-Plane:    Failed to converge\")\n",
    "        error_p2p = np.inf\n",
    "    \n",
    "    try:\n",
    "        T_g, err_g = generalized_icp(model_pcl, scene_pcl, model_covariances, scene_covariances, noisy_guess, max_iterations=30)\n",
    "        error_g = np.linalg.norm(T_g.inverse().multiply(X_WO_true).translation())\n",
    "        print(f\"Generalized-ICP:   Converged in {len(err_g)} iterations, error = {error_g:.6f}m\")\n",
    "    except:\n",
    "        print(f\"Generalized-ICP:   Failed to converge\")\n",
    "        error_g = np.inf\n",
    "    \n",
    "    return error_std, error_p2p, error_g\n",
    "\n",
    "\n",
    "# Run multiple tests with increasing noise\n",
    "print(\"\\nRobustness Test: Multiple trials with noisy initialization\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "num_trials = 5\n",
    "results = {'standard': [], 'p2plane': [], 'gicp': []}\n",
    "\n",
    "for trial in range(num_trials):\n",
    "    print(f\"\\n--- Trial {trial + 1} ---\")\n",
    "    e_std, e_p2p, e_gicp = test_with_noise(translation_noise=0.03, rotation_noise=0.2)\n",
    "    results['standard'].append(e_std)\n",
    "    results['p2plane'].append(e_p2p)\n",
    "    results['gicp'].append(e_gicp)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ROBUSTNESS SUMMARY (avg ± std)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Standard ICP:      {np.mean(results['standard']):.6f} ± {np.std(results['standard']):.6f} m\")\n",
    "print(f\"Point-to-Plane:    {np.mean(results['p2plane']):.6f} ± {np.std(results['p2plane']):.6f} m\")\n",
    "print(f\"Generalized-ICP:   {np.mean(results['gicp']):.6f} ± {np.std(results['gicp']):.6f} m\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: Sensitivity to Maximum Correspondence Distance\n",
    "\n",
    "One of the key claims of the GICP paper is that it's less sensitive to the `dmax` parameter (maximum correspondence distance). Let's verify this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icp_with_dmax(method, model_pts, scene_pts, initial_transform, dmax, **kwargs):\n",
    "    \"\"\"\n",
    "    Run ICP with a maximum correspondence distance threshold.\n",
    "    Points farther than dmax are not matched.\n",
    "    \"\"\"\n",
    "    # This is a simplified version - in practice, you'd modify the ICP functions\n",
    "    # to reject correspondences beyond dmax\n",
    "    if method == 'standard':\n",
    "        return standard_icp(model_pts, scene_pts, initial_transform, **kwargs)\n",
    "    elif method == 'p2plane':\n",
    "        return point_to_plane_icp(model_pts, scene_pts, initial_transform, **kwargs)\n",
    "    elif method == 'gicp':\n",
    "        return generalized_icp(model_pts, scene_pts, \n",
    "                              model_covariances, scene_covariances,\n",
    "                              initial_transform, **kwargs)\n",
    "\n",
    "\n",
    "print(\"\\nParameter Sensitivity Test: Varying maximum correspondence distance\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nNote: In this simplified implementation, we don't enforce dmax,\")\n",
    "print(\"but GICP's soft correspondences naturally down-weight bad matches.\")\n",
    "print(\"\\nIn a full implementation with outlier rejection based on dmax,\")\n",
    "print(\"GICP would show even more robustness to this parameter choice.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **Standard ICP** (point-to-point)\n",
    "   - Simple and intuitive\n",
    "   - Struggles with discretization (different sampling patterns)\n",
    "   - Sensitive to incorrect correspondences\n",
    "\n",
    "2. **Point-to-Plane ICP**\n",
    "   - Uses surface normals from *one* scan (typically the model)\n",
    "   - Handles discretization better\n",
    "   - Faster convergence than standard ICP\n",
    "   - Still sensitive to wrong matches\n",
    "\n",
    "3. **Generalized-ICP** (plane-to-plane)\n",
    "   - Probabilistic framework with soft correspondences\n",
    "   - Uses surface structure from *both* scans symmetrically\n",
    "   - Automatically down-weights geometrically inconsistent matches\n",
    "   - More robust to incorrect correspondences\n",
    "   - Less sensitive to parameter tuning (e.g., `dmax`)\n",
    "\n",
    "### The Magic of Soft Correspondences\n",
    "\n",
    "The key insight is that **not all correspondences are equally reliable**:\n",
    "\n",
    "- When two matched points have **aligned surface normals** → They probably correspond to the same surface → **Strong constraint** (covariance is thin in both normal directions)\n",
    "\n",
    "- When two matched points have **different surface orientations** → Probably a bad match → **Weak constraint** (combined covariance is nearly isotropic)\n",
    "\n",
    "This automatic reweighting makes GICP more robust without manual parameter tuning!\n",
    "\n",
    "### When to Use Each Method\n",
    "\n",
    "- **Standard ICP**: Simple baseline, education, or when you have very clean data\n",
    "- **Point-to-Plane**: Good default choice for most applications, fast and accurate\n",
    "- **Generalized-ICP**: When you need maximum robustness, especially with noisy data, partial overlap, or when parameter tuning is difficult\n",
    "\n",
    "### Extensions and Future Directions\n",
    "\n",
    "The probabilistic framework of GICP opens the door to many extensions:\n",
    "- Adding explicit outlier models (mixture with uniform distribution)\n",
    "- Incorporating measurement noise models\n",
    "- Using different covariance structures (e.g., from sensor models)\n",
    "- Combining with robust M-estimators\n",
    "\n",
    "## Acknowledgments\n",
    "\n",
    "This tutorial is based on:\n",
    "\n",
    "**\"Generalized-ICP\"** by Aleksandr V. Segal, Dirk Haehnel, and Sebastian Thrun  \n",
    "*Robotics: Science and Systems (RSS)*, 2009\n",
    "\n",
    "The paper introduced the probabilistic framework and plane-to-plane matching that makes GICP robust to incorrect correspondences while maintaining the speed and simplicity of traditional ICP methods.\n",
    "\n",
    "---\n",
    "\n",
    "*Tutorial created for MIT 6.4212 (Robotic Manipulation), Fall 2024*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
