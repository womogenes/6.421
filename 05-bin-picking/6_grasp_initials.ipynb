{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d4b6c1f077f543baa491a61ac103a7fd",
    "colab_type": "text",
    "deepnote_cell_type": "markdown",
    "id": "EgiF12Hf1Dhs"
   },
   "source": [
    "# Sampling Grasp Meshes\n",
    "\n",
    "In previous chapters, we manually specified grasps for the objects our robot was manipulating. This is fine when you are only manipulating a fixed object in a fixed scene, but we want our robots to be able to manipulate all sorts of objects in scenes we have not seen before. In this notebook, we will build familiarity with methods for generating grasp poses from arbitary meshes. \n",
    "\n",
    "\n",
    "**Learning Objectives:**\n",
    "1. Antipodal grasp sampling on a mesh\n",
    "2. Heuristic design for grasp filtering\n",
    "\n",
    "**What you'll build:** A simulation of the IIWA grasping and reorienting meshes corresponding to your initials. \n",
    "\n",
    "**Reference:** Make sure you understand the full grasp sampling demo in [Chapter 5](https://manipulation.mit.edu/clutter.html#grasp_sampling), many of the same principles apply. It will also be helpful, but not necessary, to have solved [Exercise 4.11](https://manipulation.mit.edu/pose.html#exercises).\n",
    "\n",
    "Your end result will look something like this, where the letters are spawned laying down on the table, and the iiwa will pick them up from above:\n",
    "\n",
    "![geometry_pick_and_place_point_clouds.png](https://raw.githubusercontent.com/RussTedrake/manipulation/master/book/figures/exercises/clutter_sampling_grasps_letters.png\n",
    ")\n",
    "\n",
    "Let's start by getting our imports out of the way and launching Meshcat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "09d3a26a2fe84566b26c83c31693574a",
    "colab": {},
    "colab_type": "code",
    "deepnote_cell_type": "code",
    "id": "eeMrMI0-1Dhu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "INFO:drake:Meshcat listening for connections at http://localhost:7000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import mpld3\n",
    "import numpy as np\n",
    "import trimesh\n",
    "from pydrake.all import (\n",
    "    AddFrameTriadIllustration,\n",
    "    BasicVector,\n",
    "    Context,\n",
    "    DiagramBuilder,\n",
    "    Integrator,\n",
    "    JacobianWrtVariable,\n",
    "    LeafSystem,\n",
    "    ModelInstanceIndex,\n",
    "    MultibodyPlant,\n",
    "    Parser,\n",
    "    PiecewisePolynomial,\n",
    "    PiecewisePose,\n",
    "    RigidTransform,\n",
    "    RotationMatrix,\n",
    "    Simulator,\n",
    "    StartMeshcat,\n",
    "    TrajectorySource,\n",
    ")\n",
    "\n",
    "from manipulation import running_as_notebook\n",
    "from manipulation.exercises.clutter.test_grasp_letters import TestLetterGrasp\n",
    "from manipulation.exercises.grader import Grader\n",
    "from manipulation.letter_generation import create_sdf_asset_from_letter\n",
    "from manipulation.station import LoadScenario, MakeHardwareStation\n",
    "\n",
    "if running_as_notebook:\n",
    "    mpld3.enable_notebook()\n",
    "\n",
    "# Start the visualizer.\n",
    "meshcat = StartMeshcat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "cc51b754026a4a418b07d392c3593de2",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Mesh Pre-Processing\n",
    "\n",
    "The first step will be load in the geometry of the part we are manipulating. Because the focus of this excercise is on grasp sampling, we will assume access to the ground truth pose of the part on the table and its geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "014000ffafbe465586f46161248ba4a5",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# TODO fill in your initials here.\n",
    "initials = \"WF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "798bdf842050483195c1882a658d2e91",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('assets/F.sdf')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_sdf_asset_from_letter(\n",
    "    text=initials[0],\n",
    "    font_name=\"DejaVu Sans\",\n",
    "    letter_height_meters=0.25,\n",
    "    extrusion_depth_meters=0.07,\n",
    "    output_dir=\"assets\",\n",
    "    include_normals=True,\n",
    "    mu_static=1.17,\n",
    "    mass=0.1,\n",
    ")\n",
    "create_sdf_asset_from_letter(\n",
    "    text=initials[1],\n",
    "    font_name=\"DejaVu Sans\",\n",
    "    letter_height_meters=0.25,\n",
    "    extrusion_depth_meters=0.07,\n",
    "    output_dir=\"assets\",\n",
    "    include_normals=True,\n",
    "    mu_static=1.17,\n",
    "    mass=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "1eb43d8708b6496cb1a7da2af3b2c02e",
    "code_folding": [],
    "deepnote_cell_type": "code",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: load your first initial with trimesh.load(...) as a mesh.\n",
    "# To do this, you should make sure to use the kwargs force=\"mesh\".\n",
    "# See the docs for more info at https://trimesh.org/. (see exercise 4.1)\n",
    "\n",
    "def load_first_initial() -> trimesh.Trimesh:\n",
    "    return trimesh.load(\"assets/W.obj\", force=\"mesh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4a3719b1e1db43a48bac3994953ea410",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Grasp Sampling\n",
    "\n",
    "The next task will be to find candidate grasps. We are looking for collinear, antipodal points that can fit within the width of the gripper and do not put the gripper in collision. From these points, we can define gripper poses that we command the robot to achieve. We will break this into three steps. \n",
    "\n",
    "1. Finding Pairs of Collinear Points via ray casting\n",
    "2. Taking a pair of colinear points and using them to compute a gripper pose\n",
    "2. Filtering grasps on antipodality, finger width, and collision\n",
    "\n",
    "**Reference:** You will need to call the following functions from `trimesh` when sampling colinear points:\n",
    "\n",
    "- [sample_surface](https://trimesh.org/trimesh.sample.html#trimesh.sample.sample_surface)\n",
    "\n",
    "- [intersects_location](https://trimesh.org/trimesh.ray.ray_pyembree.html#trimesh.ray.ray_pyembree.RayMeshIntersector.intersects_location)\n",
    "\n",
    "And constructing the grasp transform from a point and its normal is demonstrated in the demo from [Example 5.12 in the textbook](https://manipulation.mit.edu/clutter.html#grasp_sampling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_id": "5b3a6bd1e9094bcebce10f7b6e74548d",
    "code_folding": [],
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Structure: (point_1, point_2, normal_1, normal_2)\n",
    "AntipodeCandidateType = Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]\n",
    "\n",
    "\n",
    "def sample_colinear_points(\n",
    "    mesh: trimesh.Trimesh, n_sample_points: int\n",
    ") -> List[AntipodeCandidateType]:\n",
    "    \"\"\"\n",
    "    Compute n_sample_points point pairs for the mesh that are colinear.\n",
    "    This is done by sampling points from the surface and casting a ray along the normal vector of that point\n",
    "    until another point on the mesh surface is hit. This function returns\n",
    "    a list of length n_sample_points of tuples, with every tuple having the structure:\n",
    "    (point_1, point_2, normal_1, normal_2)\n",
    "\n",
    "    Note that the returned points will be expressed in the object frame.\n",
    "    \"\"\"\n",
    "    candidates = []\n",
    "\n",
    "    # Use proper surface sampling instead of random vertex selection\n",
    "    points, face_indices = trimesh.sample.sample_surface(mesh, n_sample_points)\n",
    "    \n",
    "    # Get normals for the sampled faces\n",
    "    normals = mesh.face_normals[face_indices]\n",
    "\n",
    "    for i in range(n_sample_points):\n",
    "        # Cast ray with proper 2D array format\n",
    "        ray_intersector = mesh.ray.intersects_location\n",
    "        hits, ray_indices, face_hit_indices = ray_intersector(\n",
    "            ray_origins=points[i:i+1], \n",
    "            ray_directions=(-normals[i]).reshape(1, -1)\n",
    "        )\n",
    "\n",
    "        # If no hits are found, skip this point\n",
    "        if len(hits) == 0:\n",
    "            continue\n",
    "\n",
    "        # Get the face normal from the hit face\n",
    "        face_normal = mesh.face_normals[face_hit_indices[0]]\n",
    "\n",
    "        # Add the tuple of the two points and their normals to the candidates list\n",
    "        candidates.append((points[i], hits[0], normals[i], face_normal))\n",
    "        \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_initial = load_first_initial()\n",
    "pt1, pt2, norm1, norm2 = sample_colinear_points(first_initial, 1)[0]\n",
    "pose1 = RigidTransform(p=pt1)\n",
    "pose2 = RigidTransform(p=pt2)\n",
    "AddMeshcatTriad(meshcat, \"name1\", length=0.1, radius=0.001, X_PT=X_WO1initial @ pose1)\n",
    "AddMeshcatTriad(meshcat, \"name2\", length=0.1, radius=0.001, X_PT=X_WO1initial @ pose2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "cell_id": "1193e56b25ad4b80b5bddac04b7f057d",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "def compute_grasp_from_points(\n",
    "    antipodal_pt: AntipodeCandidateType,\n",
    ") -> RigidTransform | None:\n",
    "    \"\"\"\n",
    "    Given the tuple of antipodal points and their normals on the object O, compute the grasp X_OG.\n",
    "    \"\"\"\n",
    "    z_axis_O = np.array([0.0, 0.0, 1.0])\n",
    "\n",
    "    # TODO: the x-axis of frame G is given by the normal of the sampled point in frame O\n",
    "    x_axis_G = -antipodal_pt[2]\n",
    "\n",
    "    # TODO: if the x-axis of frame G is parallel to the frame O z-axis, return None\n",
    "    # TODO: the y-axis of frame G should point along the -z axis of the O, such\n",
    "    #       that we pick up the object from above.\n",
    "    #       The x and y axis have to be orthogonal, so project. (Hint: Gram-Schmidt)\n",
    "    if np.dot(x_axis_G, z_axis_O) > 0.99:\n",
    "        return None\n",
    "    \n",
    "    y_axis_G = -z_axis_O\n",
    "    # Project\n",
    "    y_axis_G = y_axis_G - np.dot(y_axis_G, x_axis_G) * x_axis_G\n",
    "\n",
    "    # TODO: the z-axis of frame G is orthogonal to the x- and y-axis of frame G\n",
    "    z_axis_G = np.cross(x_axis_G, y_axis_G)\n",
    "    z_axis_G = z_axis_G / np.linalg.norm(z_axis_G)\n",
    "\n",
    "    # TODO: construct the rotation matrix R_OG\n",
    "    R_OG = RotationMatrix(np.column_stack((x_axis_G, y_axis_G, z_axis_G)))\n",
    "\n",
    "    # TODO: define p_OG_O by computing the median of the two colinear points.\n",
    "    p_OG_O = np.mean([antipodal_pt[0], antipodal_pt[1]], axis=0)\n",
    "\n",
    "    # TODO: define the transform X_OG, then add an offset of -0.1m in the y-axis to account for finger length\n",
    "    # return the resulting transform\n",
    "    X_OG = RigidTransform(R_OG, p_OG_O) @ RigidTransform(p=[0, -0.11, 0])\n",
    "    return X_OG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grasp=RigidTransform(\n",
      "  R=RotationMatrix([\n",
      "    [0.0, 0.0, -1.0],\n",
      "    [1.0, 0.0, 0.0],\n",
      "    [0.0, -1.0, 0.0],\n",
      "  ]),\n",
      "  p=[0.24085824169625414, 0.01983983084726885, 0.147346322318334],\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "grasp = compute_grasp_from_points((pt1, pt2, norm1, norm2))\n",
    "print(f\"{grasp=}\")\n",
    "AddMeshcatTriad(meshcat, \"name\", length=0.2, radius=0.001, X_PT=X_WO1initial @ grasp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "cell_id": "f7fe5d75a9f4464db3556595310dbc22",
    "code_folding": [],
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "def check_collision_free(X_WG: RigidTransform) -> bool:\n",
    "    \"\"\"\n",
    "    Checks if the gripper collides with the table. The table can be represented as a flat plane centered at the\n",
    "    origin with a normal vector pointing in the z-axis in world coordinates.\n",
    "    params:\n",
    "        X_WG (ndarray): (4x4) matrix describing gripper frame in the world coordinates\n",
    "    returns:\n",
    "        True if the gripper is in a collision free pose, False otherwise\n",
    "    \"\"\"\n",
    "    gripper_vertices = np.array([[-0.073, -0.085383, -0.025], [0.073, 0.069, 0.025]])\n",
    "\n",
    "    # vertices modeling the gripper collision body in homogenous coordinates\n",
    "    verts_h = np.hstack((gripper_vertices, np.ones((gripper_vertices.shape[0], 1))))\n",
    "\n",
    "    # TODO: map the gripper vertices to the world frame\n",
    "    # print(f\"{X_WG=}, {verts_h=}\")\n",
    "    verts_w = X_WG @ verts_h.T\n",
    "\n",
    "    # TODO: the gripper is collision free if all the vertices are above z=0.\n",
    "    # return true if collision free, false otherwise\n",
    "    return np.all(verts_w[2, :] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.False_"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_collision_free(np.eye(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "cell_id": "25a2b3c12dd243b893bf34e984f0c63e",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "def get_filtered_grasps(\n",
    "    candidate_list: List[AntipodeCandidateType],\n",
    "    antipodal_thresh: float,\n",
    "    z_axis_thresh: float,\n",
    "    max_pt_dist: float,\n",
    "    min_pt_dist: float,\n",
    "    X_WO: RigidTransform,\n",
    ") -> List[RigidTransform]:\n",
    "    \"\"\"\n",
    "    Return a list of grasps filtered on the following criteria\n",
    "    (1) Antipodality: antipodality is a good heuristic for finding grasps with a large total wrench cone\n",
    "    (2) Point Distance: pairs of points too far apart won't fit inside the gripper.\n",
    "        Points too close together are \"false positives\", that appear due to the numerics of the ray casting.\n",
    "    (3) Collision:\n",
    "    \"\"\"\n",
    "    filtered_candidates = []\n",
    "    for candidate in candidate_list:\n",
    "        # TODO: compute the dot product of the normals.\n",
    "        # If the points are roughly antipodal, their dot product will be less than the antipodal_thresh.\n",
    "        dot_product = np.dot(candidate[2], candidate[3])\n",
    "        if not dot_product < antipodal_thresh:\n",
    "            continue\n",
    "\n",
    "        # TODO: compute the distance between the point pairs. check that it is between\n",
    "        # max_pt_dist and min_pt_dist.\n",
    "        pt_dist = np.linalg.norm(candidate[0] - candidate[1])\n",
    "        if not min_pt_dist < pt_dist < max_pt_dist:\n",
    "            continue\n",
    "\n",
    "        # TODO: compute the grasp corresponding to the candidate list\n",
    "        # if the grasp computation fails (returns None), then `continue` to the next candidate\n",
    "        X_OG = compute_grasp_from_points(candidate)\n",
    "        if X_OG is None:\n",
    "            continue\n",
    "\n",
    "        # TODO: map the grasp to the world frame and check if it is collision free.\n",
    "        X_WG = X_WO @ X_OG\n",
    "        # Get X_WG as a 4x4 homogenous transform\n",
    "        X_WG_homogenous = X_WG.GetAsMatrix34()\n",
    "        if not check_collision_free(X_WG_homogenous):\n",
    "            continue\n",
    "\n",
    "        # TODO: If a candidate passes all three checks, add the grasp in world-frame to `filtered_candidates`\n",
    "        filtered_candidates.append(X_WG)\n",
    "        \n",
    "    return filtered_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "cell_id": "487ddaa057a1423daf8756bd042e16c0",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "def sample_grasp(\n",
    "    mesh: trimesh.Trimesh, X_WO: RigidTransform, n_sample_pts: int = 500\n",
    ") -> RigidTransform:\n",
    "    colinear_pts = sample_colinear_points(mesh, n_sample_points=n_sample_pts)\n",
    "    candidate_grasps = get_filtered_grasps(\n",
    "        colinear_pts,\n",
    "        antipodal_thresh=-0.95,\n",
    "        z_axis_thresh=0.8,\n",
    "        max_pt_dist=0.04,\n",
    "        min_pt_dist=0.005,\n",
    "        X_WO=X_WO,\n",
    "    )\n",
    "    return candidate_grasps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RigidTransform(\n",
       "  R=RotationMatrix([\n",
       "    [-0.9704312823081307, 0.0, 0.2413775596815018],\n",
       "    [-0.24137755968150176, 0.0, -0.9704312823081308],\n",
       "    [0.0, -1.0, 0.0],\n",
       "  ]),\n",
       "  p=[0.2250466962697874, 0.047040313244144094, 0.15033527258221518],\n",
       ")"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_grasp(load_first_initial(), RigidTransform(), 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "cell_id": "ec66cc3c528648839350493ec16b25a5",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "def compute_prepick_pose(X_WG: RigidTransform) -> RigidTransform:\n",
    "    X_GGprepick = RigidTransform([0, -0.17, 0.0])\n",
    "    return X_WG @ X_GGprepick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "730cad6576dc4086bc8d56db7cca9d68",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Building the Diagram\n",
    "\n",
    "The next few steps should look familiar. We will define a jacobian pseudo-inverse based controller, and define a yaml with all the geometries in our scene. The last step will be to use the grasps to define a robot trajectory.\n",
    "\n",
    "**Fill out the keyframes so that the robot starts at the initial pose. Then it:**\n",
    "\n",
    "**(1) goes to a randomly sampled grasp.**\n",
    "\n",
    "**(2) rotates the letter 30 degrees clockwise about the gripper y-axis.**\n",
    "\n",
    "When the robot is done, the first and second initial should have the same orientation.\n",
    "If you find that the robot's fingers are bumping into the letter on its' way to manipulate it, try adjusting the `opened` constant, which controls the finger width when the robot is not grasping something. It may be helpful to go to a pre-pick pose before step 1 and step 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "cell_id": "6e8c3bb84bcb4ed1801028d3f80cc16d",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "class PseudoInverseController(LeafSystem):\n",
    "    def __init__(self, plant: MultibodyPlant) -> None:\n",
    "        LeafSystem.__init__(self)\n",
    "        self._plant = plant\n",
    "        self._plant_context = plant.CreateDefaultContext()\n",
    "        self._iiwa = plant.GetModelInstanceByName(\"iiwa\")\n",
    "        self._G = plant.GetBodyByName(\"body\").body_frame()\n",
    "        self._W = plant.world_frame()\n",
    "\n",
    "        self.V_G_port = self.DeclareVectorInputPort(\"V_WG\", 6)\n",
    "        self.q_port = self.DeclareVectorInputPort(\"iiwa.position\", 7)\n",
    "        self.DeclareVectorOutputPort(\"iiwa.velocity\", 7, self.CalcOutput)\n",
    "        self.iiwa_start = plant.GetJointByName(\"iiwa_joint_1\").velocity_start()\n",
    "        self.iiwa_end = plant.GetJointByName(\"iiwa_joint_7\").velocity_start()\n",
    "\n",
    "    def CalcOutput(self, context: Context, output: BasicVector) -> None:\n",
    "        V_G = self.V_G_port.Eval(context)\n",
    "        q = self.q_port.Eval(context)\n",
    "        self._plant.SetPositions(self._plant_context, self._iiwa, q)\n",
    "        J_G = self._plant.CalcJacobianSpatialVelocity(\n",
    "            self._plant_context,\n",
    "            JacobianWrtVariable.kV,\n",
    "            self._G,\n",
    "            [0, 0, 0],\n",
    "            self._W,\n",
    "            self._W,\n",
    "        )\n",
    "        J_G = J_G[:, self.iiwa_start : self.iiwa_end + 1]  # Only iiwa terms.\n",
    "        v = np.linalg.pinv(J_G).dot(V_G)\n",
    "        output.SetFromVector(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "cell_id": "017d0eb0fb264b3a9eac80ce9c50632f",
    "code_folding": [],
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "scenario_yaml = f\"\"\"directives:\n",
    "    - add_model:\n",
    "        name: iiwa\n",
    "        file: package://drake_models/iiwa_description/sdf/iiwa7_no_collision.sdf\n",
    "        default_joint_positions:\n",
    "            iiwa_joint_1: [-1.57]\n",
    "            iiwa_joint_2: [0.1]\n",
    "            iiwa_joint_3: [0]\n",
    "            iiwa_joint_4: [-1.2]\n",
    "            iiwa_joint_5: [0]\n",
    "            iiwa_joint_6: [ 1.6]\n",
    "            iiwa_joint_7: [0]\n",
    "    - add_weld:\n",
    "        parent: world\n",
    "        child: iiwa::iiwa_link_0\n",
    "        X_PC:\n",
    "            translation: [0, -0.5, 0]\n",
    "            rotation: !Rpy {{ deg: [0, 0, 180] }}\n",
    "    - add_model:\n",
    "        name: wsg\n",
    "        file: package://manipulation/hydro/schunk_wsg_50_with_tip.sdf\n",
    "    - add_weld:\n",
    "        parent: iiwa::iiwa_link_7\n",
    "        child: wsg::body\n",
    "        X_PC:\n",
    "            translation: [0, 0, 0.09]\n",
    "            rotation: !Rpy {{deg: [90, 0, 90]}}\n",
    "    - add_model:\n",
    "        name: table\n",
    "        file: file://{Path.cwd()}/assets/table.sdf\n",
    "    - add_weld:\n",
    "        parent: world\n",
    "        child: table::table_link\n",
    "        X_PC:\n",
    "            translation: [0.0, 0.0, -0.05]\n",
    "            rotation: !Rpy {{ deg: [0, 0, -90] }}\n",
    "    - add_model:\n",
    "        name: {initials[0]}_letter\n",
    "        file: file://{Path.cwd()}/assets/{initials[0]}.sdf\n",
    "        default_free_body_pose:\n",
    "            {initials[0]}_body_link:\n",
    "                translation: [-0.2, 0, 0]\n",
    "                rotation: !Rpy {{ deg: [0, 0, 30] }}\n",
    "    - add_model:\n",
    "        name: {initials[1]}_letter\n",
    "        file: file://{Path.cwd()}/assets/{initials[1]}.sdf\n",
    "        default_free_body_pose:\n",
    "            {initials[1]}_body_link:\n",
    "                translation: [0.25, 0, 0]\n",
    "                rotation: !Rpy {{ deg: [0, 0, 0] }}\n",
    "model_drivers:\n",
    "    iiwa: !IiwaDriver\n",
    "        control_mode: position_only\n",
    "        hand_model_name: wsg\n",
    "    wsg: !SchunkWsgDriver {{}}\n",
    "\"\"\"\n",
    "with open(\"scene.yaml\", \"w\") as f:\n",
    "    f.write(scenario_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample grasp pose: RigidTransform(\n",
      "  R=RotationMatrix([\n",
      "    [-0.7197293632651987, 0.0, 0.6942547397417403],\n",
      "    [-0.6942547397417402, 0.0, -0.7197293632651988],\n",
      "    [0.0, -1.0, 0.0],\n",
      "  ]),\n",
      "  p=[-0.10198958181823367, 0.2297343053690234, 0.14024163553808994],\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from manipulation.meshcat_utils import AddMeshcatTriad\n",
    "\n",
    "grasp_pose = sample_grasp(load_first_initial(), X_WO1initial, 500)\n",
    "print(f\"sample grasp pose: {grasp_pose}\")\n",
    "\n",
    "AddMeshcatTriad(\n",
    "    meshcat,\n",
    "    \"name\",\n",
    "    length=1.0,\n",
    "    radius=0.001,\n",
    "X_PT=grasp_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "cell_id": "bb6b835df062419cbbd4de876bb643dd",
    "code_folding": [],
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "station = MakeHardwareStation(LoadScenario(filename=\"scene.yaml\"), meshcat=meshcat)\n",
    "builder = DiagramBuilder()\n",
    "builder.AddSystem(station)\n",
    "\n",
    "plant = station.GetSubsystemByName(\"plant\")\n",
    "temp_context = station.CreateDefaultContext()\n",
    "temp_plant_context = plant.GetMyContextFromRoot(temp_context)\n",
    "X_WGinitial = plant.EvalBodyPoseInWorld(temp_plant_context, plant.GetBodyByName(\"body\"))\n",
    "\n",
    "model_instance0 = plant.GetModelInstanceByName(f\"{initials[0]}_letter\")\n",
    "model_instance1 = plant.GetModelInstanceByName(f\"{initials[1]}_letter\")\n",
    "X_WO1initial = plant.EvalBodyPoseInWorld(\n",
    "    temp_plant_context, plant.GetBodyByName(f\"{initials[0]}_body_link\", model_instance0)\n",
    ")\n",
    "X_WO2initial = plant.EvalBodyPoseInWorld(\n",
    "    temp_plant_context, plant.GetBodyByName(f\"{initials[1]}_body_link\", model_instance1)\n",
    ")\n",
    "\n",
    "opened = 0.05\n",
    "closed = 0.0\n",
    "\n",
    "# TODO: redefine `keyframes` so the robot performs the behavior described above.\n",
    "# `keyframes` is a list of 2-tuples. The first element in each tuple is a\n",
    "# gripper pose in the world frame. the second element is a float corresponding to the wsg position.\n",
    "# you can use `sample_grasp` to get a grasp pose.\n",
    "# a helper function to go to prepick poses has been provided (`compute_prepick_pose`).\n",
    "\n",
    "X_WG_prepick_pose = compute_prepick_pose(grasp_pose)\n",
    "target_pose = grasp_pose @ \\\n",
    "    RigidTransform(R=RotationMatrix.MakeYRotation(np.pi/6), p=[0, -0.0, 0])\n",
    "\n",
    "keyframes = [\n",
    "    (X_WGinitial, opened),\n",
    "    (X_WG_prepick_pose, opened),\n",
    "    (grasp_pose, opened),\n",
    "    (grasp_pose, closed),\n",
    "    (compute_prepick_pose(target_pose), closed),\n",
    "    (target_pose, closed),\n",
    "    (target_pose, opened),\n",
    "    (X_WG_prepick_pose, opened),\n",
    "    (X_WGinitial, opened),\n",
    "]\n",
    "\n",
    "sample_times = [3 * i for i in range(len(keyframes))]\n",
    "robot_position_trajectory = PiecewisePose.MakeLinear(\n",
    "    sample_times, [kf[0] for kf in keyframes]\n",
    ")\n",
    "traj_V_G = robot_position_trajectory.MakeDerivative()\n",
    "gripper_values = np.array([kf[1] for kf in keyframes])[None]\n",
    "traj_wsg_command = PiecewisePolynomial.FirstOrderHold(sample_times, gripper_values)\n",
    "V_G_source = builder.AddSystem(TrajectorySource(traj_V_G))\n",
    "controller = builder.AddSystem(PseudoInverseController(plant))\n",
    "integrator = builder.AddSystem(Integrator(7))\n",
    "wsg_source = builder.AddSystem(TrajectorySource(traj_wsg_command))\n",
    "\n",
    "builder.Connect(V_G_source.get_output_port(), controller.GetInputPort(\"V_WG\"))\n",
    "builder.Connect(controller.get_output_port(), integrator.get_input_port())\n",
    "builder.Connect(integrator.get_output_port(), station.GetInputPort(\"iiwa.position\"))\n",
    "builder.Connect(\n",
    "    station.GetOutputPort(\"iiwa.position_measured\"),\n",
    "    controller.GetInputPort(\"iiwa.position\"),\n",
    ")\n",
    "\n",
    "# visualize axes (useful for debugging)\n",
    "scenegraph = station.GetSubsystemByName(\"scene_graph\")\n",
    "AddFrameTriadIllustration(\n",
    "    scene_graph=scenegraph,\n",
    "    body=plant.GetBodyByName(f\"{initials[0]}_body_link\", model_instance0),\n",
    "    length=0.1,\n",
    ")\n",
    "AddFrameTriadIllustration(\n",
    "    scene_graph=scenegraph,\n",
    "    body=plant.GetBodyByName(f\"{initials[1]}_body_link\", model_instance1),\n",
    "    length=0.1,\n",
    ")\n",
    "AddFrameTriadIllustration(\n",
    "    scene_graph=scenegraph, body=plant.GetBodyByName(\"body\"), length=0.1\n",
    ")\n",
    "\n",
    "builder.Connect(wsg_source.get_output_port(), station.GetInputPort(\"wsg.position\"))\n",
    "diagram = builder.Build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "cell_id": "892b6625706f4dacb709c83c984d9dd2",
    "deepnote_cell_type": "code",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sanity check, simulation will run for 24.0 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the simulator.\n",
    "simulator = Simulator(diagram)\n",
    "context = simulator.get_mutable_context()\n",
    "station_context = station.GetMyContextFromRoot(context)\n",
    "integrator.set_integral_value(\n",
    "    integrator.GetMyContextFromRoot(context),\n",
    "    plant.GetPositions(\n",
    "        plant.GetMyContextFromRoot(context),\n",
    "        plant.GetModelInstanceByName(\"iiwa\"),\n",
    "    ),\n",
    ")\n",
    "diagram.ForcedPublish(context)\n",
    "print(f\"sanity check, simulation will run for {traj_V_G.end_time()} seconds\")\n",
    "\n",
    "# run simulation!\n",
    "meshcat.StartRecording()\n",
    "if running_as_notebook:\n",
    "    simulator.set_target_realtime_rate(1.0)\n",
    "simulator.AdvanceTo(traj_V_G.end_time())\n",
    "meshcat.StopRecording()\n",
    "meshcat.PublishRecording()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "95957c23ba5643d3b10dea88b2b48157",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Gradescope Verification\n",
    "\n",
    "Take a video of the trajectory and upload it to gradescope as an mp4, the file should be (much) smaller than 500MB. The robot should grasp the first initial using an antipodal grasp and rotate is so it has the same orientation as the second initial. Optionally, consider adding more advanced heuristics, like checking for collision between the gripper and the mesh in the pick pose as is done in chapter 5. "
   ]
  }
 ],
 "metadata": {
  "deepnote_notebook_id": "48bc82853a2e4247b15f91cc221d1cdc",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": "4",
 "nbformat_minor": "0"
}
